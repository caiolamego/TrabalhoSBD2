{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddf68e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# import psycopg2\n",
    "import pyspark\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from pyspark.sql.functions import col, lit, split, when\n",
    "from pyspark.sql.types import IntegerType, StringType, StructField, StructType\n",
    "\n",
    "DB_HOST = \"postgres\"\n",
    "DB_PORT = 5432\n",
    "DB_NAME = \"data_warehouse\"\n",
    "DB_USER = \"dw_user\"\n",
    "DB_PASS = \"dw_password\"\n",
    "\n",
    "DB_URL_JDBC = f\"jdbc:postgresql://{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "DB_PROPERTIES = {\n",
    "    \"user\": DB_USER,\n",
    "    \"password\": DB_PASS,\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "# caminho para a tabelona silver\n",
    "SILVER_TABLE_PATH = \"/opt/airflow/data_layer/silver/resultado.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88815574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pais_map_data():\n",
    "    return [\n",
    "        ('USA', 'Estados Unidos'), ('CHN', 'China'), ('DEU', 'Alemanha'), ('JPN', 'Japão'),\n",
    "        ('GBR', 'Reino Unido'), ('FRA', 'França'), ('ITA', 'Itália'), ('IND', 'Índia'),\n",
    "        ('CAN', 'Canadá'), ('AUS', 'Austrália'), ('KOR', 'Coreia do Sul'), ('ESP', 'Espanha'),\n",
    "        ('NLD', 'Holanda'), ('IRL', 'Irlanda'), ('CHE', 'Suíça'), ('LUX', 'Luxemburgo'),\n",
    "        ('SWE', 'Suécia'), ('DNK', 'Dinamarca'), ('FIN', 'Finlândia'), ('POL', 'Polônia'),\n",
    "        ('AUT', 'Áustria'), ('BEL', 'Bélgica'), ('CZE', 'República Tcheca'), ('HUN', 'Hungria'),\n",
    "        ('ROU', 'Romênia'), ('PRT', 'Portugal'), ('GRC', 'Grécia'), ('BRA', 'Brasil'),\n",
    "        ('MEX', 'México'), ('ARG', 'Argentina'), ('COL', 'Colômbia'), ('CHL', 'Chile'),\n",
    "        ('PER', 'Peru'), ('URY', 'Uruguai'), ('TWN', 'Taiwan'), ('SGP', 'Singapura'),\n",
    "        ('HKG', 'Hong Kong'), ('THA', 'Tailândia'), ('MYS', 'Malásia'), ('VNM', 'Vietnã'),\n",
    "        ('IDN', 'Indonésia'), ('PHL', 'Filipinas'), ('SAU', 'Arábia Saudita'),\n",
    "        ('ARE', 'Emirados Árabes Unidos'), ('QAT', 'Catar'), ('KWT', 'Kuwait'),\n",
    "        ('IRN', 'Irã'), ('ISR', 'Israel'), ('NOR', 'Noruega'), ('RUS', 'Rússia'),\n",
    "        ('ZAF', 'África do Sul'), ('EGY', 'Egito'), ('NGA', 'Nigéria'),\n",
    "        ('GHA', 'Gana'), ('KEN', 'Quênia')\n",
    "    ]\n",
    "\n",
    "def get_indicator_map_data():\n",
    "    return [\n",
    "        # BOP (Balanço de Pagamentos)\n",
    "        ('CAB/BOP/NETCD_T', 'Conta Corrente, Líquida', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('CABXEF/BOP/NETCD_T', 'Conta Corrente (Excl. Financiamento Excepcional), Líquida', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('DXEF/BOP/L_NIL_T', 'Investimento Direto (Excl. Financ. Excepcional), Passivo', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('D_F5/BOP/A_NFA_T', 'Invest. Direto (Derivativos Financ.), Ativo', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('D_F5/BOP/L_NIL_T', 'Invest. Direto (Derivativos Financ.), Passivo', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('D_FL/BOP/A_NFA_T', 'Invest. Direto (Ações e Títulos), Ativo', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('D_FL/BOP/L_NIL_T', 'Invest. Direto (Ações e Títulos), Passivo', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('EO/BOP/NETCD_T', 'Erros e Omissões, Líquido', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('FAB/BOP/NNAFANIL_T', 'Conta Financeira, Líquida', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('FABXRRI/BOP/NNAFANIL_T', 'Conta Financeira (Excl. Reservas), Líquida', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('GS/BOP/CD_T', 'Bens e Serviços, Crédito', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('GS/BOP/DB_T', 'Bens e Serviços, Débito', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('GS/BOP/NETCD_T', 'Bens e Serviços, Líquido', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('IN1/BOP/CD_T', 'Renda Primária, Crédito', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('IN1/BOP/DB_T', 'Renda Primária, Débito', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('IN1/BOP/NETCD_T', 'Renda Primária, Líquida', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('IN2/BOP/CD_T', 'Renda Secundária, Crédito', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('IN2/BOP/DB_T', 'Renda Secundária, Débito', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('IN2/BOP/NETCD_T', 'Renda Secundária, Líquida', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('KAB/BOP/NETCD_T', 'Conta Capital, Líquida', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('O_F2/BOP/A_NFA_T', 'Outros Investimentos (Moeda e Depósitos), Ativo', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('O_F2/BOP/L_NIL_T', 'Outros Investimentos (Moeda e Depósitos), Passivo', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('O_F2/BOP/NNAFANIL_T', 'Outros Investimentos (Moeda e Depósitos), Líquido', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('O_F4/BOP/A_NFA_T', 'Outros Investimentos (Títulos de Dívida), Ativo', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('O_F4/BOP/L_NIL_T', 'Outros Investimentos (Títulos de Dívida), Passivo', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('O_F4/BOP/NNAFANIL_T', 'Outros Investimentos (Títulos de Dívida), Líquido', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('O_F81/BOP/A_NFA_T', 'Outros Investimentos (Créditos Comerciais), Ativo', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('O_F81/BOP/L_NIL_T', 'Outros Investimentos (Créditos Comerciais), Passivo', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('O_F81/BOP/NNAFANIL_T', 'Outros Investimentos (Créditos Comerciais), Líquido', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('PXEF/BOP/L_NIL_T', 'Invest. Carteira (Excl. Financ. Excepcional), Passivo', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('P_F3/BOP/A_NFA_T', 'Invest. Carteira (Títulos de Dívida), Ativo', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('P_F3/BOP/L_NIL_T', 'Invest. Carteira (Títulos de Dívida), Passivo', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('P_F5/BOP/A_NFA_T', 'Invest. Carteira (Ações), Ativo', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('P_F5/BOP/L_NIL_T', 'Invest. Carteira (Ações), Passivo', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('RUE/BOP/NNAFANIL_T', 'Ativos de Reserva, Líquido', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('R_F/BOP/A_T', 'Ativos de Reserva (Ativos Totais)', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('SF/BOP/CD_T', 'Serviços, Crédito', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('SF/BOP/DB_T', 'Serviços, Débito', 'BOP', 'Balanço de Pagamentos'),\n",
    "        ('SF/BOP/NETCD_T', 'Serviços, Líquido', 'BOP', 'Balanço de Pagamentos'),\n",
    "        \n",
    "        # --- ER (Exchange Rates) ---\n",
    "        ('XDC_EUR', 'Taxa de Câmbio (Moeda Local por EUR)', 'ER', 'Taxa de Câmbio'),\n",
    "        ('XDC_USD', 'Taxa de Câmbio (Moeda Local por USD)', 'ER', 'Taxa de Câmbio'),\n",
    "        ('XDC_XDR', 'Taxa de Câmbio (Moeda Local por XDR)', 'ER', 'Taxa de Câmbio'),\n",
    "        \n",
    "        # --- IIP (Posição de Investimento) ---\n",
    "        ('D/IIP/A_P', 'Investimento Direto, Ativos', 'IIP', 'Posição de Investimento'),\n",
    "        ('D/IIP/L_P', 'Investimento Direto, Passivos', 'IIP', 'Posição de Investimento'),\n",
    "        ('D_F5/IIP/A_P', 'Invest. Direto (Derivativos Financ.), Ativos', 'IIP', 'Posição de Investimento'),\n",
    "        ('D_F5/IIP/L_P', 'Invest. Direto (Derivativos Financ.), Passivos', 'IIP', 'Posição de Investimento'),\n",
    "        ('D_FL/IIP/A_P', 'Invest. Direto (Ações e Títulos), Ativos', 'IIP', 'Posição de Investimento'),\n",
    "        ('D_FL/IIP/L_P', 'Invest. Direto (Ações e Títulos), Passivos', 'IIP', 'Posição de Investimento'),\n",
    "        ('NIIP/IIP/NETAL_P', 'Posição de Investimento Internacional Líquida (NIIP)', 'IIP', 'Posição de Investimento'),\n",
    "        ('O_F12/IIP/L_P', 'Outros Investimentos (Alocação SDR), Passivos', 'IIP', 'Posição de Investimento'),\n",
    "        ('O_F2_NV/IIP/A_P', 'Outros Investimentos (Moeda e Depósitos), Ativos', 'IIP', 'Posição de Investimento'),\n",
    "        ('O_F2_NV/IIP/L_P', 'Outros Investimentos (Moeda e Depósitos), Passivos', 'IIP', 'Posição de Investimento'),\n",
    "        ('O_F4_NV/IIP/A_P', 'Outros Investimentos (Títulos de Dívida), Ativos', 'IIP', 'Posição de Investimento'),\n",
    "        ('O_F4_NV/IIP/L_P', 'Outros Investimentos (Títulos de Dívida), Passivos', 'IIP', 'Posição de Investimento'),\n",
    "        ('O_F81/IIP/A_P', 'Outros Investimentos (Créditos Comerciais), Ativos', 'IIP', 'Posição de Investimento'),\n",
    "        ('O_F81/IIP/L_P', 'Outros Investimentos (Créditos Comerciais), Passivo', 'IIP', 'Posição de Investimento'),\n",
    "        ('O_FL1/IIP/A_P', 'Outros Investimentos (Empréstimos), Ativos', 'IIP', 'Posição de Investimento'),\n",
    "        ('P_F3_MV/IIP/A_P', 'Invest. Carteira (Títulos de Dívida), Ativos', 'IIP', 'Posição de Investimento'),\n",
    "        ('P_F3_MV/IIP/L_P', 'Invest. Carteira (Títulos de Dívida), Passivos', 'IIP', 'Posição de Investimento'),\n",
    "        ('P_F5_MV/IIP/A_P', 'Invest. Carteira (Ações), Ativos', 'IIP', 'Posição de Investimento'),\n",
    "        ('P_F5_MV/IIP/L_P', 'Invest. Carteira (Ações), Passivos', 'IIP', 'Posição de Investimento'),\n",
    "        ('P_MV/IIP/A_P', 'Investimento em Carteira, Ativos (Total)', 'IIP', 'Posição de Investimento'),\n",
    "        ('P_MV/IIP/L_P', 'Investimento em Carteira, Passivos (Total)', 'IIP', 'Posição de Investimento'),\n",
    "        ('R/IIP/A_P', 'Ativos de Reserva (Total)', 'IIP', 'Posição de Investimento'),\n",
    "        ('R_F11_MV/IIP/A_P', 'Reservas (Ouro Monetário)', 'IIP', 'Posição de Investimento'),\n",
    "        ('R_F12_MV/IIP/A_P', 'Reservas (SDRs)', 'IIP', 'Posição de Investimento'),\n",
    "        ('R_FK_MV/IIP/A_P', 'Reservas (Outros Ativos)', 'IIP', 'Posição de Investimento'),\n",
    "        ('TA_AFR/IIP/A_P', 'Total Ativos (Excl. Reservas)', 'IIP', 'Posição de Investimento'),\n",
    "        ('TL_AFR/IIP/L_P', 'Total Passivos', 'IIP', 'Posição de Investimento'),\n",
    "        \n",
    "        # --- IRFCL (Reservas Internacionais) ---\n",
    "        ('IRFCLDT1_IRFCL32_USD_IRFCL13', 'Títulos nas Reservas', 'IRFCL', 'Reservas Internacionais'),\n",
    "        ('IRFCLDT1_IRFCL54_USD_IRFCL13', 'Reservas Oficiais + Outros Ativos FX', 'IRFCL', 'Reservas Internacionais'),\n",
    "        ('IRFCLDT1_IRFCL56_USD_IRFCL13', 'Ouro nas Reservas', 'IRFCL', 'Reservas Internacionais'),\n",
    "        ('IRFCLDT1_IRFCL57_USD_IRFCL13', 'Posição de Reservas no FMI', 'IRFCL', 'Reservas Internacionais'),\n",
    "        ('IRFCLDT1_IRFCL65_DIC_XDR_USD_IRFCL13', 'SDR (Holdings) nas Reservas', 'IRFCL', 'Reservas Internacionais'),\n",
    "        ('IRFCLDT1_IRFCL65_USD_IRFCL13', 'Reservas Oficiais (Total)', 'IRFCL', 'Reservas Internacionais'),\n",
    "        ('IRFCLDT1_IRFCLCDCFC_USD_IRFCL13', 'Moeda e Depósitos nas Reservas', 'IRFCL', 'Reservas Internacionais'),\n",
    "        ('IRFCLDT2_IRFCL151_SM1MUT3M_FO_USD_IRFCL13', 'Drenagens: Juros (1-3 Meses)', 'IRFCL', 'Reservas Internacionais'),\n",
    "        ('IRFCLDT2_IRFCL151_SM3MUTY_FO_USD_IRFCL13', 'Drenagens: Juros (3-12 Meses)', 'IRFCL', 'Reservas Internacionais'),\n",
    "        ('IRFCLDT2_IRFCL151_SUTM_FO_USD_IRFCL13', 'Drenagens: Juros (Até 1 Mês)', 'IRFCL', 'Reservas Internacionais'),\n",
    "        ('IRFCLDT2_IRFCL1_SUTM_IN_LP_USD_IRFCL13', 'Drenagens: Entradas Forwards (Até 1 Mês)', 'IRFCL', 'Reservas Internacionais'),\n",
    "        ('IRFCLDT2_IRFCL1_SUTM_SHP_USD_IRFCL13', 'Drenagens: Saídas Forwards (Até 1 Mês)', 'IRFCL', 'Reservas Internacionais'),\n",
    "        ('IRFCLDT2_IRFCL24_SM1MUT3M_USD_IRFCL13', 'Drenagens: Total (1-3 Meses)', 'IRFCL', 'Reservas Internacionais'),\n",
    "        ('IRFCLDT2_IRFCL24_SM3MUTY_USD_IRFCL13', 'Drenagens: Total (3-12 Meses)', 'IRFCL', 'Reservas Internacionais'),\n",
    "        ('IRFCLDT2_IRFCL24_SUTM_USD_IRFCL13', 'Drenagens: Total (Até 1 Mês)', 'IRFCL', 'Reservas Internacionais'),\n",
    "        ('IRFCLDT2_IRFCL26_SM1MUT3M_FO_USD_IRFCL13', 'Drenagens: Principal (1-3 Meses)', 'IRFCL', 'Reservas Internacionais'),\n",
    "        ('IRFCLDT2_IRFCL26_SM3MUTY_FO_USD_IRFCL13', 'Drenagens: Principal (3-12 Meses)', 'IRFCL', 'Reservas Internacionais'),\n",
    "        ('IRFCLDT2_IRFCL26_SUTM_FO_USD_IRFCL13', 'Drenagens: Principal (Até 1 Mês)', 'IRFCL', 'Reservas Internacionais'),\n",
    "        ('IRFCLDT2_USD_IRFCL13', 'Drenagens Líquidas de Curto Prazo (Total)', 'IRFCL', 'Reservas Internacionais'),\n",
    "        ('IRFCLDT4_IRFCL11_DIC_XDRB_USD_IRFCL13', 'Memo: Moedas da Cesta SDR', 'IRFCL', 'Reservas Internacionais'),\n",
    "        ('IRFCLDT4_IRFCL11_DIC_XXDR_USD_IRFCL13', 'Memo: Moedas Fora da Cesta SDR', 'IRFCL', 'Reservas Internacionais'),\n",
    "        ('IRFCLDT4_IRFCL68_USD_IRFCL13', 'Memo: Títulos Cedidos/em Repo', 'IRFCL', 'Reservas Internacionais'),\n",
    "        ('IRFCLDT4_IRFCL69X_USD_IRFCL13', 'Memo: Títulos Cedidos (Não Incl. Seção I)', 'IRFCL', 'Reservas Internacionais'),\n",
    "        ('IRFCLDT4_IRFCLU97_A_USD_IRFCL13', 'Memo: Derivativos (Net MTM)', 'IRFCL', 'Reservas Internacionais'),\n",
    "        \n",
    "        # --- Demografia (DM) ---\n",
    "        ('FERT_RATIO/DM/BR_L_W', 'Taxa de Fertilidade', 'DM', 'Demografia'),\n",
    "        ('LFEXP/DM/Y', 'Expectativa de Vida', 'DM', 'Demografia'),\n",
    "        ('MORT/DM/DT', 'Taxa de Mortalidade', 'DM', 'Demografia'),\n",
    "        ('POP/DM/PS', 'População Total', 'DM', 'Demografia'),\n",
    "\n",
    "        # --- Colunas de Metadados (Não são indicadores) ---\n",
    "        ('UNIT_BOP', 'Metadado: Unidade BOP', 'META', 'Metadados'),\n",
    "        ('TYPE_OF_TRANSFORMATION_ER', 'Metadado: Tipo de Transformação ER', 'META', 'Metadados'),\n",
    "        ('UNIT_IIP', 'Metadado: Unidade IIP', 'META', 'Metadados'),\n",
    "        ('SECTOR_IRFCL', 'Metadado: Setor IRFCL', 'META', 'Metadados'),\n",
    "        ('TERRITORIAL_LEVEL', 'Metadado: Nível Territorial DM', 'META', 'Metadados'),\n",
    "        ('FREQ', 'Metadado: Frequência DM', 'META', 'Metadados')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e9bec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_session(app_name=\"ETL_Silver_to_Gold\"):\n",
    "    print(\"Iniciando sessão Spark...\")\n",
    "    spark = (\n",
    "        SparkSession.builder\n",
    "        .appName(app_name)\n",
    "        .config(\"spark.driver.memory\", \"4g\")\n",
    "        .config(\"spark.executor.memory\", \"2g\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    print(\"Sessão Spark criada com sucesso.\")\n",
    "    return spark\n",
    "\n",
    "def get_db_connection():\n",
    "    return psycopg2.connect(\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT,\n",
    "        dbname=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3468049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_dw_tables(): #limpar as tabelas do DW antes de popular\n",
    "    print(\"Iniciando TRUNCATE nas tabelas do DW...\")\n",
    "    \n",
    "    sql_truncate_fato = \"TRUNCATE TABLE DW.Fato_ObservacaoEconomica;\"\n",
    "    sql_truncate_dims = \"\"\"\n",
    "    TRUNCATE TABLE DW.Dim_Pais, \n",
    "                     DW.Dim_Tempo, \n",
    "                     DW.Dim_Indicador \n",
    "    RESTART IDENTITY CASCADE;\n",
    "    \"\"\"\n",
    "    \n",
    "    conn = None\n",
    "    cursor = None\n",
    "    try:\n",
    "        conn = get_db_connection()\n",
    "        conn.autocommit = True\n",
    "        cursor = conn.cursor() #executar comandos SQL\n",
    "        \n",
    "        print(f\"Executando: {sql_truncate_fato}\")\n",
    "        cursor.execute(sql_truncate_fato)\n",
    "        print(f\"Executando: {sql_truncate_dims}\")\n",
    "        cursor.execute(sql_truncate_dims)\n",
    "        \n",
    "        print(\"Tabelas do DW truncadas com sucesso.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO ao truncar tabelas: {e}\")\n",
    "        raise e\n",
    "    finally:\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        if conn:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace1aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_dim_pais(spark: SparkSession, df_silver: DataFrame):\n",
    "    print(\"Iniciando ETL para DW.Dim_Pais...\")\n",
    "    \n",
    "    df_paises_silver = df_silver.select(col(\"COUNTRY\").alias(\"codigo_pais\")).distinct()\n",
    "    \n",
    "    schema_pais_map = StructType([\n",
    "        StructField(\"codigo_pais_map\", StringType(), False), #false e true indicaam se o campo pode ser nulo\n",
    "        StructField(\"nome_pais\", StringType(), True)\n",
    "    ])\n",
    "    pais_data = [(cod, nome) for cod, nome in get_pais_map_data()]\n",
    "    df_pais_map = spark.createDataFrame(pais_data, schema=schema_pais_map)\n",
    "    \n",
    "    df_dim_pais = df_paises_silver.join( #interação com a tabelona, através de um join\n",
    "        df_pais_map, \n",
    "        df_paises_silver.codigo_pais == df_pais_map.codigo_pais_map, \n",
    "        \"left\"\n",
    "    ).select(\"codigo_pais\", \"nome_pais\") \n",
    "    \n",
    "    print(f\"Escrevendo {df_dim_pais.count()} países em DW.Dim_Pais...\")\n",
    "    df_dim_pais.write.jdbc(\n",
    "        url=DB_URL_JDBC,\n",
    "        table=\"DW.Dim_Pais\",\n",
    "        mode=\"append\", # A tabela foi truncada, então usamos append\n",
    "        properties=DB_PROPERTIES\n",
    "    )\n",
    "    print(\"DW.Dim_Pais populada com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3747c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_dim_tempo(spark: SparkSession, df_silver: DataFrame):\n",
    "    print(\"Iniciando ETL para DW.Dim_Tempo...\")\n",
    "    \n",
    "    df_dim_tempo = (\n",
    "        df_silver.select(\"TIME_PERIOD\").distinct()\n",
    "        .withColumnRenamed(\"TIME_PERIOD\", \"periodo_completo\")\n",
    "        .filter(col(\"periodo_completo\").isNotNull())\n",
    "    )\n",
    "    \n",
    "    split_col = split(col(\"periodo_completo\"), \"-\")\n",
    "    \n",
    "    df_dim_tempo = df_dim_tempo.withColumn(\"ano\", split_col.getItem(0).cast(\"int\"))\n",
    "    df_dim_tempo = df_dim_tempo.withColumn(\n",
    "        \"trimestre\",\n",
    "        when(split_col.getItem(1).isNotNull(), split_col.getItem(1)).otherwise(lit(None))\n",
    "    )\n",
    "    # df_dim_tempo = df_dim_tempo.withColumn(\"mes\", lit(None).cast(\"int\"))\n",
    "    \n",
    "    df_dim_tempo_final = df_dim_tempo.select(\"periodo_completo\", \"ano\", \"trimestre\")\n",
    "    \n",
    "    print(f\"Escrevendo {df_dim_tempo_final.count()} períodos em DW.Dim_Tempo...\")\n",
    "    df_dim_tempo_final.write.jdbc(\n",
    "        url=DB_URL_JDBC,\n",
    "        table=\"DW.Dim_Tempo\",\n",
    "        mode=\"append\", # A tabela foi truncada, então usamos append\n",
    "        properties=DB_PROPERTIES\n",
    "    )\n",
    "    print(\"DW.Dim_Tempo populada com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de483b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_dim_indicador(spark: SparkSession, all_silver_columns: list):\n",
    "    print(\"Iniciando ETL para DW.Dim_Indicador...\")\n",
    "    \n",
    "    id_vars = ['COUNTRY', 'TIME_PERIOD', 'FREQUENCY', 'UNIT_BOP', \n",
    "               'TYPE_OF_TRANSFORMATION_ER', 'UNIT_IIP', 'SECTOR_IRFCL', \n",
    "               'TERRITORIAL_LEVEL', 'FREQ']\n",
    "    \n",
    "    indicator_codes = [c for c in all_silver_columns if c not in id_vars]\n",
    "    \n",
    "    indicator_map_dict = {cod: (nome, fonte, cat) for cod, nome, fonte, cat in get_indicator_map_data()}\n",
    "    \n",
    "    schema_indicador_data = []\n",
    "    for cod in indicator_codes:\n",
    "        nome, fonte, cat = indicator_map_dict.get(\n",
    "            cod, \n",
    "            (f\"Indicador - {cod}\", \"Desconhecida\", \"Desconhecida\")\n",
    "        )\n",
    "        schema_indicador_data.append((cod, nome, fonte, cat))\n",
    "            \n",
    "    schema_indicador = StructType([\n",
    "        StructField(\"codigo_indicador\", StringType(), False),\n",
    "        StructField(\"nome_indicador\", StringType(), True),\n",
    "        StructField(\"fonte_dados\", StringType(), True),\n",
    "        StructField(\"categoria\", StringType(), True),\n",
    "    ])\n",
    "    \n",
    "    df_dim_indicador = spark.createDataFrame(schema_indicador_data, schema=schema_indicador)\n",
    "    \n",
    "    print(f\"Escrevendo {df_dim_indicador.count()} indicadores em DW.Dim_Indicador...\")\n",
    "    df_dim_indicador.write.jdbc(\n",
    "        url=DB_URL_JDBC,\n",
    "        table=\"DW.Dim_Indicador\",\n",
    "        mode=\"append\", # A tabela foi truncada, então usamos append\n",
    "        properties=DB_PROPERTIES\n",
    "    )\n",
    "    print(\"DW.Dim_Indicador populada com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eb6159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_fato_observacao(spark: SparkSession, df_silver: DataFrame):\n",
    "    print(\"Iniciando ETL para DW.Fato_ObservacaoEconomica...\")\n",
    "    \n",
    "    print(\"Lendo Dimensões do DW (com SRKs)...\")\n",
    "\n",
    "    df_dim_pais = spark.read.jdbc(url=DB_URL_JDBC, table=\"DW.Dim_Pais\", properties=DB_PROPERTIES)\n",
    "    df_dim_tempo = spark.read.jdbc(url=DB_URL_JDBC, table=\"DW.Dim_Tempo\", properties=DB_PROPERTIES)\n",
    "    df_dim_indicador = spark.read.jdbc(url=DB_URL_JDBC, table=\"DW.Dim_Indicador\", properties=DB_PROPERTIES)\n",
    "    \n",
    "    id_vars = ['COUNTRY', 'TIME_PERIOD']\n",
    "    id_vars_meta = ['COUNTRY', 'TIME_PERIOD', 'FREQUENCY', 'UNIT_BOP', \n",
    "                    'TYPE_OF_TRANSFORMATION_ER', 'UNIT_IIP', 'SECTOR_IRFCL', \n",
    "                    'TERRITORIAL_LEVEL', 'FREQ']\n",
    "    meta_indicadores = {cod for cod, _, fonte, _ in get_indicator_map_data() if fonte == 'META'}\n",
    "    \n",
    "    measure_vars = [\n",
    "        c for c in df_silver.columns \n",
    "        if c not in id_vars_meta and c not in meta_indicadores\n",
    "    ]\n",
    "    \n",
    "    stack_expr_parts = []\n",
    "    for cod in measure_vars:\n",
    "        stack_expr_parts.append(f\"'{cod}', `{cod}`\") \n",
    "            \n",
    "    stack_expr = f\"stack({len(measure_vars)}, {', '.join(stack_expr_parts)}) as (Codigo_Indicador, Valor)\"\n",
    "    \n",
    "    df_long = df_silver.selectExpr(*id_vars, stack_expr)\n",
    "    \n",
    "    df_long_cleaned = df_long.filter(col(\"Valor\").isNotNull())\n",
    "    print(f\"Unpivot concluído. {df_long_cleaned.count()} observações de fato encontradas.\")\n",
    "    \n",
    "    print(\"Juntando Fato com Dimensões para obter SRKs...\")\n",
    "    \n",
    "    # renomeando colunas\n",
    "    df_long_renomeado = df_long_cleaned.withColumnRenamed(\"COUNTRY\", \"chave_pais\") \\\n",
    "                                     .withColumnRenamed(\"TIME_PERIOD\", \"chave_tempo\") \\\n",
    "                                     .withColumnRenamed(\"Codigo_Indicador\", \"chave_indicador\")\n",
    "\n",
    "    # Join Pais\n",
    "    # (long.chave_pais == dim.codigo_pais)\n",
    "    df_fato_join_pais = df_long_renomeado.join(\n",
    "        df_dim_pais,\n",
    "        df_long_renomeado.chave_pais == df_dim_pais.codigo_pais,\n",
    "        \"inner\"\n",
    "    ).select(\n",
    "        df_long_renomeado[\"*\"], \n",
    "        df_dim_pais.srk_pais\n",
    "    )\n",
    "\n",
    "    # Join Tempo\n",
    "    df_fato_join_tempo = df_fato_join_pais.join(\n",
    "        df_dim_tempo,\n",
    "        df_fato_join_pais.chave_tempo == df_dim_tempo.periodo_completo,\n",
    "        \"inner\"\n",
    "    ).select(\n",
    "        df_fato_join_pais[\"*\"], \n",
    "        df_dim_tempo.srk_tempo \n",
    "    )\n",
    "\n",
    "    # Join Indicador\n",
    "    df_fato_join_final = df_fato_join_tempo.join(\n",
    "        df_dim_indicador,\n",
    "        df_fato_join_tempo.chave_indicador == df_dim_indicador.codigo_indicador,\n",
    "        \"inner\"\n",
    "    ).select(\n",
    "        df_fato_join_tempo[\"*\"],    \n",
    "        df_dim_indicador.srk_indicador \n",
    "    )\n",
    "\n",
    "    # Colunas finais da Fato\n",
    "    df_fato_final = df_fato_join_final.select(\n",
    "        col(\"srk_pais\"),\n",
    "        col(\"srk_tempo\"),\n",
    "        col(\"srk_indicador\"),\n",
    "        col(\"Valor\").cast(\"decimal(30, 8)\").alias(\"valor\")\n",
    "    )\n",
    "    \n",
    "    print(f\"Escrevendo {df_fato_final.count()} linhas em DW.Fato_ObservacaoEconomica...\")\n",
    "    \n",
    "    df_fato_final.write.jdbc(\n",
    "        url=DB_URL_JDBC,\n",
    "        table=\"DW.Fato_ObservacaoEconomica\",\n",
    "        mode=\"append\", # A tabela foi truncada, então usamos append\n",
    "        properties=DB_PROPERTIES\n",
    "    )\n",
    "    print(\"DW.Fato_ObservacaoEconomica populada com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3d9345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "\n",
    "def main():\n",
    "    spark = None\n",
    "    try:\n",
    "        spark = create_spark_session()\n",
    "        \n",
    "        print(f\"Lendo tabelona Silver de: {SILVER_TABLE_PATH}\")\n",
    "\n",
    "        df_silver = spark.read.csv(SILVER_TABLE_PATH, header=True, inferSchema=True)\n",
    "        \n",
    "        all_columns = df_silver.columns\n",
    "        \n",
    "        #Limpar tabelas antes de popular\n",
    "        truncate_dw_tables()\n",
    "        \n",
    "        # Popular Dim\n",
    "        etl_dim_pais(spark, df_silver)\n",
    "        etl_dim_tempo(spark, df_silver)\n",
    "        etl_dim_indicador(spark, all_columns)\n",
    "        \n",
    "        # Popular Fato\n",
    "        etl_fato_observacao(spark, df_silver)\n",
    "        \n",
    "        print(\"\\n--- SUCESSO: ETL Silver-para-Gold concluído. ---\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n--- ERRO FATAL NO ETL: {e} ---\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "    finally:\n",
    "        if spark:\n",
    "            print(\"Parando sessão Spark.\")\n",
    "            spark.stop()\n",
    "\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
