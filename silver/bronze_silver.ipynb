{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85ff26a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Path: /home/mateus/Documentos/Faculdade/bancos2/TrabalhoSBD2\n",
      "Data Path: /home/mateus/Documentos/Faculdade/bancos2/TrabalhoSBD2/base_dados/Resultados\n",
      "Spark Config Path: /home/mateus/Documentos/Faculdade/bancos2/TrabalhoSBD2/spark_config\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Define paths\n",
    "if 'AIRFLOW_HOME' in os.environ:\n",
    "    # Running in Airflow\n",
    "    BASE_PATH = Path('/opt/airflow')\n",
    "    DATA_PATH = BASE_PATH / 'base_dados' / 'Resultados'\n",
    "    SPARK_CONFIG_PATH = BASE_PATH / 'spark_config'\n",
    "else:\n",
    "    # Running manually\n",
    "    BASE_PATH = Path.cwd().parent\n",
    "    DATA_PATH = BASE_PATH / 'base_dados' / 'Resultados'\n",
    "    SPARK_CONFIG_PATH = BASE_PATH / 'spark_config'\n",
    "\n",
    "# Add spark_config to path\n",
    "sys.path.insert(0, str(SPARK_CONFIG_PATH))\n",
    "\n",
    "print(f\"Base Path: {BASE_PATH}\")\n",
    "print(f\"Data Path: {DATA_PATH}\")\n",
    "print(f\"Spark Config Path: {SPARK_CONFIG_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "35c3f1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:config:Spark Session criada: Bronze_Silver_Analysis\n",
      "INFO:config:Spark UI disponível em: http://172.29.99.42:4040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version: 3.5.1\n",
      "Spark UI: http://172.29.99.42:4040\n"
     ]
    }
   ],
   "source": [
    "from config import SparkConfig, DataSchemas\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Create Spark session\n",
    "spark_config = SparkConfig(app_name=\"Bronze_Silver_Analysis\")\n",
    "spark = spark_config.create_spark_session()\n",
    "spark_config.configure_for_banking_data()\n",
    "\n",
    "print(f\"Spark Version: {spark.version}\")\n",
    "print(f\"Spark UI: {spark.sparkContext.uiWebUrl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "979e48f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/17 12:35:33 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:35:33 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:35:33 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:35:34 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:35:34 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:35:34 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:35:34 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:35:35 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:35:35 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records loaded: 180,804\n",
      "Total records loaded: 107,805\n",
      "Total records loaded: 96,247\n",
      "Total records loaded: 26,418\n",
      "Total records loaded: 23,072\n"
     ]
    }
   ],
   "source": [
    "# Load BOP data\n",
    "bop_file = DATA_PATH / 'BOP.csv'\n",
    "irfcl_file = DATA_PATH / 'IRFCL.csv'\n",
    "iip_file = DATA_PATH / 'IIP.csv'\n",
    "er_file = DATA_PATH / 'ER.csv'\n",
    "dm_file = DATA_PATH / 'demography.csv'\n",
    "\n",
    "df_bop = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(str(bop_file))\n",
    "\n",
    "df_irfcl = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(str(irfcl_file))\n",
    "df_iip = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(str(iip_file))\n",
    "df_er = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(str(er_file))\n",
    "\n",
    "df_dm = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(str(dm_file))\n",
    "\n",
    "print(f\"Total records loaded: {df_bop.count():,}\")\n",
    "print(f\"Total records loaded: {df_irfcl.count():,}\")\n",
    "print(f\"Total records loaded: {df_iip.count():,}\")\n",
    "print(f\"Total records loaded: {df_er.count():,}\")\n",
    "print(f\"Total records loaded: {df_dm.count():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57ba6f4",
   "metadata": {},
   "source": [
    "## Redimencionando BOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f24c432",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicadores_nome = {\n",
    "    # (1) Sinal geral do país\n",
    "    \"CAB\": \"conta_corrente\",\n",
    "    \"CABXEF\": \"corrente_limpa\",\n",
    "    \"KAB\": \"conta_capital\",\n",
    "    \"FAB\": \"conta_financeira\",\n",
    "    \"FABXRRI\": \"financeira_mercado\",\n",
    "    \"EO\": \"erros_omissões\",\n",
    "\n",
    "    # (2) Componentes do CAB\n",
    "    \"SF\": \"saldo_comercial\",\n",
    "    \"GS\": \"bens_serviços\",\n",
    "    \"IN1\": \"renda_primária\",\n",
    "    \"IN2\": \"renda_secundária\",\n",
    "\n",
    "    # (3) Composição do financiamento\n",
    "    \"DXEF\": \"investimento_direto\",\n",
    "    \"D_F5\": \"direto_acoes\",\n",
    "    \"D_FL\": \"direto_divida\",\n",
    "    \"PXEF\": \"portfólio_limpo\",\n",
    "    \"P_F5\": \"portfólio_acoes\",\n",
    "    \"P_F3\": \"portfólio_divida\",\n",
    "    \"O_F4\": \"outros_emprestimos\",\n",
    "    \"O_F2\": \"outros_depositos\",\n",
    "    \"O_F81\": \"credito_comercial\",\n",
    "\n",
    "    # (4) Reservas\n",
    "    \"RUE\": \"uso_reservas\",\n",
    "    \"R_F\": \"ativos_reservas\"\n",
    "}\n",
    "\n",
    "\n",
    "accounting_entries = {\n",
    "    \"CD_T\": \"credito_entrada\",\n",
    "    \"DB_T\": \"debito_saida\",\n",
    "    \"NETCD_T\": \"saldo_liquido\",\n",
    "    \"A_NFA_T\": \"ativos_aquisicao\",\n",
    "    \"L_NIL_T\": \"passivos_incorporacao\",\n",
    "    \"NNAFANIL_T\": \"conta_financeira\",\n",
    "    \"A_T\": \"ativos_total\",\n",
    "    \"L_T\": \"passivos_total\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0863c436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1108:==================>                                     (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+---------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+-------------------+--------------------+\n",
      "|COUNTRY|UNIT|FREQUENCY|TIME_PERIOD|     CAB/BOP/NETCD_T|  CABXEF/BOP/NETCD_T|    DXEF/BOP/L_NIL_T|    D_F5/BOP/A_NFA_T|    D_F5/BOP/L_NIL_T|    D_FL/BOP/A_NFA_T|    D_FL/BOP/L_NIL_T|      EO/BOP/NETCD_T|  FAB/BOP/NNAFANIL_T|FABXRRI/BOP/NNAFANIL_T|         GS/BOP/CD_T|         GS/BOP/DB_T|      GS/BOP/NETCD_T|        IN1/BOP/CD_T|        IN1/BOP/DB_T|     IN1/BOP/NETCD_T|        IN2/BOP/CD_T|        IN2/BOP/DB_T|     IN2/BOP/NETCD_T|     KAB/BOP/NETCD_T|    O_F2/BOP/A_NFA_T|    O_F2/BOP/L_NIL_T| O_F2/BOP/NNAFANIL_T|    O_F4/BOP/A_NFA_T|    O_F4/BOP/L_NIL_T| O_F4/BOP/NNAFANIL_T|   O_F81/BOP/A_NFA_T|   O_F81/BOP/L_NIL_T|O_F81/BOP/NNAFANIL_T|    PXEF/BOP/L_NIL_T|    P_F3/BOP/A_NFA_T|    P_F3/BOP/L_NIL_T|    P_F5/BOP/A_NFA_T|    P_F5/BOP/L_NIL_T|  RUE/BOP/NNAFANIL_T|         R_F/BOP/A_T|        SF/BOP/CD_T|        SF/BOP/DB_T|      SF/BOP/NETCD_T|\n",
      "+-------+----+---------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+-------------------+--------------------+\n",
      "|    ESP| USD|        Q|    2012-Q4| 6.954168581249998E9| 6.954168581249992E9|     1.5555138225E10|-8.476487043749998E9|   1.586245464375E10| 2.240686799999999E9|-3.086131124999999E8| 4.918359393749999E9|   1.531265649375E10|       1.5264678825E10|   1.051177755375E11|9.831143004374997E10|  6.80634549374999E9|2.059020005624999E10|1.804997699999999E10| 2.540223056249999E9| 4.996161018749999E9| 7.388560987499998E9|-2.392399968749999E9| 3.440128518749999E9|-7.170716437499998E8|   -1.10462747175E11|  1.0974567553125E11| 3.914718431249999E9|4.397736853124999E10|-4.00626500999999...|                NULL|                NULL|                NULL|5.692226223749998E10|   1.562904976875E10|5.190146403749999E10| 2.375542949999999E9| 5.020798199999999E9|  6.00507108999052E7| 4.797766874999999E7|               NULL|               NULL|                NULL|\n",
      "|    IRL| USD|        Q|    2005-Q3|  -1.4846441151515E9|-1.484644115151495E9|1.596754874545439E10| 2.553295096969671E9|-1.244319636363624E9|3.260605415757543E10|1.721186838181801E10| 3.231571290909059E9|   1.7896244181818E9|   1.801823630303013E9|3.972551435151475E10|3.385037379393906E10|  5.87514055757571E9|1.423526062424228E10|2.127542593939373E10|-7.040165315151445E9| 1.277257509090896E9| 1.596876866666651E9|-3.196193575757544E8|   4.2697242424242E7|2.048857675757555E10| 5.944676066666607E9|1.454390069090895E10| 8.857847921212032E9|2.066790517575737E10|-1.18100572545453...| -2.19585818181816E7| 5.087071454545404E8| -5.30665727272722E8|3.931440090302991E10|-9.795967333333235E9|2.230259959999978E10|1.747903112727255E10|1.701180130303013E10|-1.155902052737061E7|  -1.2199212121212E7|2.098264484848464E9|1.883558351515133E9| 2.147061333333312E8|\n",
      "|    POL| USD|        Q|    2023-Q2|             2.844E9|             2.844E9|             7.715E9|             2.768E9|             7.285E9|             1.552E9|               4.3E8|               1.8E7|             4.352E9|  -9.198000000000008E9|          1.19199E11|          1.04933E11|           1.4266E10|             5.572E9|           1.6064E10|          -1.0492E10|             3.113E9|             4.043E9|              -9.3E8|              1.49E9|             2.971E9|             3.963E9|             -9.92E8|             1.536E9|              8.79E8|              6.57E8|             -3.11E8|             -1.78E8|             -1.33E8|             7.546E9|             2.702E9|             7.058E9|              2.97E8|              4.88E8|1.355074631062945E10|            1.355E10|             1.65E8|             4.86E8|             -3.21E8|\n",
      "|    BEL| USD|        Q|    2016-Q3|-1.911668484848505E9|-1.910551856060625E9| 3.294054924242459E8| 5.114159848484902E8| 7.335134507575834E9|-2.971349204545485E9|-7.005729015151588E9|-8.732037121212212E8|-2.815021174242454E9|  -2.774822537878817E9|9.392858037878886E10|9.469570435606158E10|  -7.6712397727274E8|1.627821446969714E10|1.541729367424258E10| 8.609207954545544E8| 2.596161931818209E9| 4.600510606060654E9|-2.004348674242445E9|-3.014897727272759E7|-1.92194146969699E10|-1.86130852651517...|-6.063294318181881E8|-3.754105984848524E9| 2.188592424242447E8|-3.972965227272769E9|-9.089358333333428E8| 1.898268939393959E7|-9.279185227272824E8|-7.196672537878863E9|-8.797918219697062E9|-4.086861363636406E8| 6.340218257575824E9|-6.787986401515222E9|-4.003841355627638E7|-4.019863636363678E7|4.098027651515194E8|3.517380681818218E8| 5.806469696969757E7|\n",
      "|    DEU| USD|        Q|    2021-Q3|6.773376093939484E10|6.773376093939478E10|3.992944107727326E10|4.805725663030367E10|1.477388141060626E10|1.215930637121228E10|2.515438086818215E10|-5.13956139393946...|1.840222314696994E10|  -1.82423432570165...|4.554193642333394E11|4.084277414333388E11| 4.69928015984854E10| 7.35853166181828E10| 3.36865243015156E10| 3.98987923166672E10|2.682002312727309E10|4.597785610303092E10|-1.91578329757578...| 2.064076146969725E9|-3.11191012015155...|4.832838028181883E10|-7.94474814833344E10| 2.45284388727276E10|2.149185397575786E10| 3.036584896969738E9| 4.373342378787937E8| 6.571801553030391E9|-6.134467315151597E9|-4.981602396969763E9| 1.645602684848507E9|-9.185197793939516E9|5.653399653484924E10| 4.203595396969753E9|3.664464165570276E10|3.677733392878837E10|4.012630042424296E9|2.483728407575791E9| 1.528901634848505E9|\n",
      "|    DEU| USD|        Q|    2023-Q2|4.326083870484013E10| 4.32608387048401E10|2.718975883064605E10|1.711294570806508E10|  8.68656999838738E9|-6.434093080645372E8|1.850210015322641E10|-1.842044922580705E9|3.706843236935605E10|  3.587524015000118E10|4.870782650693708E11|4.488405914193695E11| 3.82387623290335E10|1.091770880709713E11|9.314737800000305E10|1.602971007096827E10|3.523183084193664E10|4.623946453709829E10|-1.10065450161293...|-4.350361412903368E9|-5.94647374209696...|-1.15981332022584...|5.651659460161475E10|-1.512175175806501E9|3.154665231774297E10|-3.30599161725817...|-1.01758829145164...|-3.336801233871077E9|-6.839081680645385E9|3.520570254516244E10|5.210526716290493E10|4.365820655161433E10| 1.839867564516189E8|-8.451415327419631E9| 1.190546712122882E9| 1.193192219354878E9| 4.89361225000016E9|2.947054140322677E9| 1.947646788709741E9|\n",
      "|    USA| USD|        Q|    2010-Q4|          -9.7831E10|          -9.7831E10|           7.1143E10|           2.4183E10|           5.4892E10|            2.443E10|           1.6251E10|          -1.5383E10|          -1.1469E11|            -1.1449E11|          5.08123E11|          6.23492E11|         -1.15369E11|          1.85197E11|          1.43511E11|           4.1686E10|           2.4208E10|           4.8356E10|          -2.4148E10|            -1.476E9|           5.4535E10|           3.2037E10|           2.2498E10|           2.5798E10|           4.1903E10|          -1.6105E10|             4.601E9|              4.24E9|              3.61E8|          1.72716E11|           4.4943E10|          1.34214E11|           2.8701E10|           3.8502E10|-1.951796715475697E8|              -2.0E8|            3.958E9|          1.5379E10|          -1.1421E10|\n",
      "|    USA| USD|        Q|    2012-Q2|         -1.16778E11|         -1.16778E11|           9.4985E10|           9.0407E10|           7.0492E10|             7.242E9|           2.4493E10|           7.2263E10|          -4.6309E10|            -4.9598E10|          5.65897E11|          7.07427E11|          -1.4153E11|          1.95136E11|          1.47225E11|           4.7911E10|           2.6932E10|           5.0091E10|          -2.3159E10|            -1.794E9|         -3.29146E11|         -1.80247E11|         -1.48899E11|              3.89E9|          -4.6983E10|           5.0873E10|             1.596E9|              2.09E9|             -4.94E8|             7.887E9|             1.174E9|          -2.2822E10|           5.3636E10|           3.0709E10| 3.289546768630608E9|             3.289E9|            3.988E9|          1.4859E10|          -1.0871E10|\n",
      "|    AUS| USD|        Q|    2017-Q1|-5.335704599956506E9|-5.335704599956513E9| 9.521061297238111E9|-1.846012839865651E9| 5.090175798595065E9| 6.782354235138578E8| 4.430885498643047E9| 2.582599243949975E9|-2.862229267722727E9|  -5.625186087981415E9|7.350556381005272E10|6.818501530894568E10|  5.32054850110703E9|1.026674136063212E10|2.040010905138889E10|-1.01333676907567...| 1.868746988139859E9| 2.391632398446632E9|-5.228854103067731E8|-1.091239117161961E8|-1.290541817032514E9|-4.956802128719714E9|   3.6662603116872E9| -6.88844692708488E9| -5.59866291499484E9| -1.28978401209004E9|-6.464076159299673E8| 5.835098057046598E7|-7.047585965004333E8|1.347756090189269E10| 9.675653505502724E9| 6.752799842382109E9| 1.887692111701698E9| 6.724761059510586E9| 2.763353315801166E9| 2.762956820258688E9|9.321000792425086E7|2.015761146979734E8|-1.083661067737225E8|\n",
      "|    AUS| USD|        Q|    2020-Q4| 8.175195397800977E9|   8.1759254563291E9| 2.869130015481143E9| 1.824416261752513E9| 9.316276877240423E9|-1.444055768606031E9|-6.446416803231169E9|  3.00127060906946E9|1.110638038817166E10|  1.167655609862733E10|8.230168804967828E10|7.223929135670715E10|1.006239669297115E10|1.072894012913763E10|1.234967006154682E10|-1.620729932409195E9| 1.720017892232461E9|  1.98575919646532E9| -2.65741304232859E8|  -7.0085618698776E7| 5.771112664727337E9| 7.631301794357351E9|-1.860189129630013E9|-1.33768624106007...|-1.21328426786974...|-1.244019731903274E9| 2.226678510742363E8|  1.10968896273062E8| 1.116989548011743E8|3.691759964958026E10|1.028725471962972E10|3.224376495260564E10| 3.78674057946543E10| 4.673834696974625E9|-5.728470728080136E8|-5.701757104556674E8| 1.40171237397552E8|2.175574413774505E8|-7.738620397989851E7|\n",
      "|    FIN| USD|        Q|    2025-Q1|-1.002881230158759E9|-1.003933571428599E9| 1.639547698412745E9| 4.157800357142975E9| 1.081806825396856E9|-3.620053968254071E8| 5.577408730158888E8| 5.040714682539826E8|-3.609530555555658E8|  -9.934101587301869E8|2.955289988095322E10| 2.89867402777786E10|   5.6615960317462E8| 7.731551309524029E9| 8.883865000000252E9|-1.151261349206382E9| 9.407930952381219E8| 1.358572579365118E9|-4.167271428571547E8| 1.378567063492103E8|1.602400051587347E10|2.547192043650866E10| -9.44791992063519E9| 4.408257579365205E9|-8.944900793651047E7| 4.497706587301715E9| 6.492945634920819E8| 9.050134920635179E7| 5.587932142857301E8|1.207982543650828E10| 7.949385952381178E9|1.328475619047657E10| 4.530329166666795E9|-1.204930753968288E9| 6.314728936606789E8| 6.335094444444624E8|  4209365.079365199|1.315426587301625E8|-1.273332936507973E8|\n",
      "|    CHE| USD|        Q|    2022-Q2|1.367435519242207E10|1.367435519242173E10|  1.49213938276052E9| 8.001797049575644E9|-2.30203010509799E10|-6.485976602690169E9|2.451244043374045E10|-9.045504864774237E9| 4.867942461966576E9|   2.848609246590219E9|1.407332377599654E11|1.221277229972869E11|1.860551476267863E10|4.275467828007775E10|4.581066432524886E10|-3.055986045171088E9|1.221982737080594E10|1.409500089589173E10|-1.875173525085788E9| 2.390921343187261E8|-5.766764436983195E9|-1.15087825025860...| 5.742018065602899E9|-3.615968765999596E9|  -5.4080537113773E9| 1.792084945377705E9|                NULL|                NULL|                NULL| 2.122401906735774E9| 6.070203803379716E9|-2.106337765041873E9|-1.688445389425777E9| 4.228739671777646E9| 2.016425367465823E9| 2.019333215376357E9|1.866656337992183E9|5.094727438339637E8| 1.357183594158212E9|\n",
      "|    SWE| USD|        Q|    2025-Q1|1.116746887401699E10|1.116746887401701E10| 7.615323910048444E9| 6.235307445713676E9| 6.209652753317467E9| -6.63220613574116E9| 1.405671156730977E9|-2.32083208526757...|-1.20362640957119...|  -1.39261909789874...|8.337962289296408E10|7.688271248902045E10|  6.49691040394364E9|2.209767865850116E10|1.418592133193301E10| 7.911757326568145E9| 1.579261666594378E9| 4.820460523089164E9|-3.241198856494787E9|   4681513.210987068|3.185835281261654E10|3.791445193261363E10|-6.056099119997091E9| 3.467315944585462E9| 4.150629612861135E8| 3.052252983299349E9| 1.719987953716649E8|-1.155116569678949E9| 1.327115365050614E9| 7.089964497511475E9| 5.606205700421234E9| 8.088812156207676E9|-6.977795440976225E9|-9.988476586962008E8| 1.586402700720174E9| 1.889926883275479E9|2.322030552649586E8|2.046757575843546E8| 2.752729768060396E7|\n",
      "|    PRT| USD|        Q|    2016-Q2|-4.516941538461598E7|  -4.6298650769228E7| 1.206023390769247E9| 7.486830600000098E8|-2.936012000000038E7|-2.077793107692335E8| 1.235383510769247E9|-1.964869569230795E8| 1.196989507692323E8|  -2.540779615384649E8| 2.12804408230772E10|2.056789329538488E10|   7.1254752769232E8| 2.278797006153876E9| 4.192850983076978E9|-1.914053976923102E9| 2.278797006153876E9| 1.123589207692322E9| 1.155207798461554E9| 3.624845584615432E8| 1.468006000000019E8| 3.020704653846193E9|-2.873904053846192E9|-1.693853076923099E8| 5.601007507692381E8| -7.29486058461548E8| 9.790470784615513E8|-2.744041984615421E8| 1.253451276923093E9|-1.420578113846172E9| 1.392347229230787E9|-1.176663270769246E9|-5.126728646153913E8|-2.427856076923109E8| 3.782087810583823E8| 3.782938538461588E8|1.919700153846179E7|1.185697153846169E8|-9.937271384615515E7|\n",
      "|    PRT| USD|        Q|    2010-Q4|-6.545501669696983E9|-6.545501669696984E9| 2.014313960606065E9| -3.89008441212122E9|-8.529933696969714E8| 1.237383693939396E9| 2.867307330303036E9|-6.261623303030314E8|-5.681642142424254E9|  -5.438511866666678E9|1.918012639090913E10|2.422066523636368E10|-5.040538845454556E9| 4.354612648484857E9| 5.885382596969709E9|-1.530769948484852E9| 2.067286478787883E9| 2.041479354545459E9| 2.580712424242429E7| 1.490021857575761E9| 5.528157666666678E8|-4.182112396969705E9| 4.734928163636373E9|-5.313551054545465E9| -2.21805441515152E9|-3.094138369696976E9| 2.186814212121216E8| 1.045867666666669E8| 1.140946545454548E8|-3.599414696969704E9|-6.023926106060618E9|-4.255458960606069E9|-6.492529151515164E8| 6.560442636363649E8|-2.415821803818593E8|-2.417720060606065E8|3.124020303030309E7|9.100406969696988E7|-5.976386666666679E7|\n",
      "|    BRA| USD|        Q|    2006-Q4|  2.63494241538207E9|  2.63494241538206E9|  7.17795775372798E9|        1.7037549E10|  6.82026827493843E9|  3.69102140002441E9|  3.57689478789547E8|  2.27399291629478E9|  4.98547587997685E9|  -7.116815816280049E9| 4.18351303030379E10|  3.3042363441405E10|  8.79276686163291E9|  1.58038034827257E9|  8.83306487281231E9| -7.25268452453974E9|  1.23760707828889E9|           1.42747E8|  1.09486007828889E9|        7.65405483E7| -3.38597205508452E8|  4.72919501306069E8| -8.11516706814521E8|  1.29360077194696E9| 1.06461630843317E10| -9.35256231238473E9|                NULL|  4.25632144337727E9| -4.25632144337727E9|          7.358703E9|      1.3339721066E8|  4.38937117379614E9|      4.9797578934E8|  2.96933182620386E9|1.210225860618955E10| 1.21022916962569E10|          2.14401E8|          2.32379E8|           -1.7978E7|\n",
      "|    THA| USD|        Q|    2004-Q2|  -4.2107741749638E8|-4.210774174964205E8|  1.46156243339043E9|  6.51157950676115E7|   1.4221299587905E9| -3.21227977194937E7|  3.94324745999358E7|    1243390.95507111| -4.19834026541309E8|  -1.264275746158093E9| 2.75622928000706E10|  2.6647986730327E10|   9.1430606974352E8|  8.67539304045119E8|  2.74545496546236E9| -1.87791566141724E9|  6.20104255357502E8|  7.75720811802015E7|    5.425321741773E8|                NULL| -1.85782648141929E9| -6.42953211320516E8| -1.21487327009878E9| -1.00023231598702E8| -1.09351771617552E9|  9.93494484576818E8|  1.33762114342783E8|  2.83784530317571E8| -1.50022415974787E8|  9.40312855844622E7|  5.25849204154251E8|  1.63050547557616E8|   1.6392074718624E8| -6.90192619731537E7| 8.443100563025091E8|  8.44441719616784E8| 2.73739940318596E7| 3.11164988689529E8| -2.83790994657669E8|\n",
      "|    NOR| USD|        Q|    2002-Q3| 5.771745891659977E9| 5.771745891659978E9|  4.75030968722919E8| 1.321952438421419E9| 1.555081794644139E7| 3.814602350964682E8| 4.594801507764776E8|-4.052250748300043E9| 1.650646222879108E9|   -4.43929332830036E8|2.010747343069652E10| 1.39791220300596E10|  6.12835140063692E9| 2.465269839919614E9|   2.3427240779827E9| 1.225457619369142E8| 4.743664038534129E8| 9.535176747672694E8|-4.791512709138564E8|-6.884892048082598E7|-1.791135236292685E9| 5.047104357950588E9|-6.838239594243273E9| 8.835921591978436E9| 5.067838781879177E9| 3.768082810099259E9|-3.298900012227994E8| -2.67155077541429E7|-3.031744934686565E8|-7.227807520747715E8|-1.645994268792565E9|-5.355063718479688E8| 2.062011877103348E9|-1.872743802268027E8| 2.056141327360372E9| 2.094575555709144E9|7.815282865391058E7|1.314509311882952E8|-5.329810253438459E7|\n",
      "|    NOR| USD|        Q|    2008-Q4| 1.65978420794507E10| 1.65978420794507E10| 1.55736635605689E10|  7.05625306522805E9|1.051177047572339E10|-7.268268759195681E7|  5.06189308484551E9|-4.185875429131925E9|1.240534575772437E10|   4.862972045120158E9| 4.38957822461991E10|2.890387444825894E10|1.499190779794015E10| 1.21581657675331E10| 8.659980382540457E9| 3.498185384992642E9| 6.258950465914661E8| 2.518146150073564E9|-1.892251103482098E9|  -6620892.594409021| 3.760078469838154E9| 1.04833742030407E10|-6.723295733202547E9|-3.22599313388916E10|-1.18465424227562...|-2.04133889161353...|-2.911868563021087E9|-5.526238352133396E8|-2.359244727807748E9|-1.513094654242275E9|1.740456105934281E10| 4.491760666993622E9|1.498808239333006E10|-6.004855321235897E9| 7.829665840265832E9| 7.542373712604214E9|2.839627268268758E7| 5.06130456105934E7|-2.221677292790583E7|\n",
      "|    PRT| USD|        Q|    2021-Q3| 8.782048712121329E8|  8.78204871212133E8| 4.196522606060662E9| 5.622868772727348E8| 3.411442815151561E9| 5.233865272727343E8| 7.850797909091014E8| 6.636635469697058E8| 3.407906419697015E9|     9.6100468119534E7|2.862004841363675E10|2.876386182878826E10| -1.43813415151517E8| 3.007114934848525E9| 3.765082360606111E9|-7.579674257575859E8|  3.60830216212126E9| 1.828316450000024E9| 1.779985712121236E9| 1.866038001515176E9| 3.108491604545496E9|-3.140319163636406E9| 6.248810768181902E9|-1.119858560606076E8| 1.968593469696996E8|-3.088452030303072E8|-2.510840772727306E8| 7.544310303030404E8|-1.005515107575771E9| -7.30383541212131E9|-4.886119719697035E9|-7.607965421212223E9| 2.268008284848515E9| 3.041300090909132E8| 3.312250573411926E9| 3.321854130303075E9|4.479434242424302E7|1.921441530303056E8|-1.473498106060626E8|\n",
      "+-------+----+---------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, concat_ws, lit, create_map, first\n",
    "from itertools import chain\n",
    "\n",
    "# Substitui 0 por nulo\n",
    "bop_null = df_bop.withColumn(\"value\", when(col(\"value\") == 0, None).otherwise(col(\"value\")))\n",
    "\n",
    "# Mapas de nomes amigáveis (se tiver)\n",
    "indicadores_map = create_map([lit(x) for x in chain(*indicadores_nome.items())])    # Não estou usando no momento\n",
    "contas_map = create_map([lit(x) for x in chain(*accounting_entries.items())])       # Não estou usando no momento\n",
    "\n",
    "# Adiciona colunas de nomes e chave para pivot\n",
    "bop_null = bop_null \\\n",
    "    .withColumn(\"INDICATOR_NOME\", indicadores_map[col(\"INDICATOR\")]) \\\n",
    "    .withColumn(\"ENTRY_NOME\", contas_map[col(\"BOP_ACCOUNTING_ENTRY\")]) \\\n",
    "    .withColumn(\"pivot_key\", concat_ws(\"/BOP/\", col(\"INDICATOR\"), col(\"BOP_ACCOUNTING_ENTRY\")))\n",
    "\n",
    "# Pivot final\n",
    "pivoted_BOP = bop_null.groupBy(\"COUNTRY\", \"UNIT\", \"FREQUENCY\", \"TIME_PERIOD\") \\\n",
    "    .pivot(\"pivot_key\") \\\n",
    "    .agg(first(\"value\"))\n",
    "\n",
    "pivoted_BOP.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "88eabedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+----+-----------+--------------------+----------+----------+-----------+\n",
      "|REF_AREA|TERRITORIAL_LEVEL|FREQ|TIME_PERIOD|FERT_RATIO/DM/BR_L_W|LFEXP/DM/Y|MORT/DM/DT|  POP/DM/PS|\n",
      "+--------+-----------------+----+-----------+--------------------+----------+----------+-----------+\n",
      "|     BRA|             CTRY|   A|       2005|                NULL|      75.8|  582311.0|9.4147106E7|\n",
      "|     NOR|             CTRY|   A|       2009|                1.98|      83.2|   19912.0|  2395053.0|\n",
      "|     DNK|             CTRY|   A|       2003|                1.76|      75.0|   28146.0|  2662423.0|\n",
      "|     NLD|             CTRY|   A|       2020|             1.54489|      83.1|   84361.0|  8759554.0|\n",
      "|     BEL|             CTRY|   A|       2022|             1.52949|      79.7|   59528.0|  5733645.0|\n",
      "|     JPN|             CTRY|   A|       2018|                1.42|      87.3|  698300.0|   6.1671E7|\n",
      "|     AUT|             CTRY|   A|       2004|                1.42|      82.1|   39676.0|  4189973.0|\n",
      "|     ROU|             CTRY|   A|       2021|             1.80713|      76.6|  160629.0|  9387590.0|\n",
      "|     POL|             CTRY|   A|       2020|             1.39491|      80.7|  227611.0|1.9584757E7|\n",
      "|     AUS|             CTRY|   A|       2011|                1.92|      84.2|   75377.0|1.1118234E7|\n",
      "|     ARG|             CTRY|   A|       2021|                NULL|      NULL|      NULL|2.2492818E7|\n",
      "|     ARG|             CTRY|   A|       2015|                NULL|      72.6|      NULL|2.1131346E7|\n",
      "|     FIN|             CTRY|   A|       2010|                1.87|      76.9|   25539.0|  2625067.0|\n",
      "|     ISR|             CTRY|   A|       2023|                NULL|      NULL|   25083.0|  4706398.0|\n",
      "|     CHN|             CTRY|   A|       2013|                NULL|      77.6|      NULL|       NULL|\n",
      "|     CAN|             CTRY|   A|       2017|                1.55|     79.75|  136163.0|1.8142187E7|\n",
      "|     ITA|             CTRY|   A|       2023|                NULL|      81.0|  348450.0|3.0182369E7|\n",
      "|     CHL|             CTRY|   A|       2000|                NULL|      73.4|      NULL|  7777489.0|\n",
      "|     GRC|             CTRY|   A|       2006|                 1.4|      77.1|   55290.0|  5571325.0|\n",
      "|     RUS|             CTRY|   A|       2007|                NULL|      74.0| 1104648.0|6.7059282E7|\n",
      "+--------+-----------------+----+-----------+--------------------+----------+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, concat_ws, lit, create_map, first\n",
    "from itertools import chain\n",
    "\n",
    "# 1) Substituir 0 por null e aplicar filtros\n",
    "dm_null = (\n",
    "    df_dm\n",
    "    .withColumn(\"value\", F.when(F.col(\"value\") == 0, F.lit(None)).otherwise(F.col(\"value\")))\n",
    "    .filter(F.col(\"SEX\").isin(\"T\", \"F\", \"M\")) # SEX é ('T', 'M', 'F')\n",
    "    .filter(F.col(\"TERRITORIAL_TYPE\") == F.lit(\"TYPO_METRO\")) # apenas metropolitano\n",
    "    .drop(\"AGE\", \"SEX\", \"TERRITORIAL_TYPE\") # drop mesmas colunas do Pandas\n",
    ")\n",
    "\n",
    "# Adiciona colunas de nomes e chave para pivot\n",
    "dm_null = dm_null \\\n",
    "    .withColumn(\"pivot_key\", concat_ws(\"/DM/\", col(\"MEASURE\"), col(\"UNIT_MEASURE\")))\n",
    "\n",
    "# Pivot final\n",
    "pivoted_DM = dm_null.groupBy('REF_AREA', 'TERRITORIAL_LEVEL','FREQ','TIME_PERIOD') \\\n",
    "    .pivot(\"pivot_key\") \\\n",
    "    .agg(first(\"value\"))\n",
    "\n",
    "pivoted_DM.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cd1fd48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns in pivoted_DM are unique.\n"
     ]
    }
   ],
   "source": [
    "# verificação se todas as colunas são diferentes\n",
    "\n",
    "pivoted_DM_columns = pivoted_DM.columns\n",
    "if len(pivoted_DM_columns) == len(set(pivoted_DM_columns)):\n",
    "    print(\"All columns in pivoted_DM are unique.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cc114e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-----+\n",
      "|REF_AREA|TIME_PERIOD|count|\n",
      "+--------+-----------+-----+\n",
      "|     ESP|       2011|    1|\n",
      "|     DEU|       2003|    1|\n",
      "|     BEL|       2014|    1|\n",
      "|     CHE|       2016|    1|\n",
      "|     DEU|       2007|    1|\n",
      "|     IRL|       2022|    1|\n",
      "|     KOR|       2010|    1|\n",
      "|     FRA|       2021|    1|\n",
      "|     FRA|       2006|    1|\n",
      "|     USA|       2012|    1|\n",
      "|     FRA|       2019|    1|\n",
      "|     CHN|       2001|    1|\n",
      "|     GBR|       2000|    1|\n",
      "|     AUT|       2007|    1|\n",
      "|     CAN|       2020|    1|\n",
      "|     USA|       2009|    1|\n",
      "|     POL|       2015|    1|\n",
      "|     FRA|       2009|    1|\n",
      "|     RUS|       2001|    1|\n",
      "|     ITA|       2002|    1|\n",
      "+--------+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# opção 1 — orderBy\n",
    "pivoted_DM.groupBy('REF_AREA', 'TIME_PERIOD').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eec42371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------+-----------+---------+------------------+-----------------+------------------+\n",
      "|COUNTRY|TYPE_OF_TRANSFORMATION|TIME_PERIOD|FREQUENCY|           XDC_EUR|          XDC_USD|           XDC_XDR|\n",
      "+-------+----------------------+-----------+---------+------------------+-----------------+------------------+\n",
      "|    GBR|                EOP_RT|    2013-Q1|        Q|0.8467795265176558|0.661288189392937|0.9914008932106448|\n",
      "|    IND|                EOP_RT|    2006-Q2|        Q|        57.3165605|           45.085| 66.69733891153965|\n",
      "|    SAU|                EOP_RT|    2018-Q2|        Q|           4.37175|             3.75| 5.274647372241008|\n",
      "|    URY|                EOP_RT|    2021-Q4|        Q|         50.621557|           44.695| 62.55484658352148|\n",
      "|    CZE|                EOP_RT|    2005-Q4|        Q|        29.0064636|           24.588| 35.14278363776691|\n",
      "|    PER|                EOP_RT|    2021-Q2|        Q|         4.5848472|            3.858| 5.503142411283582|\n",
      "|    GHA|                EOP_RT|    2001-Q1|        Q|0.6363392051091572|0.720492759408013|0.9082898632420825|\n",
      "|    AUS|                EOP_RT|    2011-Q3|        Q| 1.380533687761989| 1.02239034863511| 1.596589332913428|\n",
      "|    CHN|                EOP_RT|    2003-Q2|        Q|        9.45858498|           8.2774| 11.59546570138181|\n",
      "|    CHE|                EOP_RT|    2003-Q1|        Q|        1.47485615|           1.3537| 1.859697711542847|\n",
      "|    ROU|                EOP_RT|    2005-Q1|        Q|        3.68553556|           2.8429| 4.295124567526325|\n",
      "|    CHL|                EOP_RT|    2006-Q3|        Q|         681.38652|           538.22| 794.6141864808404|\n",
      "|    ZAF|                EOP_RT|    2018-Q1|        Q| 14.62263143278295| 11.8680557039063| 17.25454507693313|\n",
      "|    VNM|                EOP_RT|    2000-Q1|        Q|        13433.4286|          14062.0| 18939.74086146056|\n",
      "|    GBR|                EOP_RT|    2002-Q3|        Q|0.6305557331969049|0.639508857197672| 0.845874263686469|\n",
      "|    POL|                EOP_RT|    2000-Q2|        Q| 4.195752919999998|           4.3907| 5.871591776802754|\n",
      "|    CZE|                EOP_RT|    2021-Q3|        Q|         25.496958|            22.02| 31.02334781653113|\n",
      "|    GHA|                EOP_RT|    2008-Q3|        Q|         1.6005057|            1.119| 1.742531950312145|\n",
      "|    GHA|                EOP_RT|    2013-Q4|        Q|        2.98106256|           2.1616| 3.328862202414411|\n",
      "|    HUN|                EOP_RT|    2009-Q1|        Q|          310.0764|            233.0| 348.3523531724732|\n",
      "+-------+----------------------+-----------+---------+------------------+-----------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, concat_ws, lit, create_map, first\n",
    "from itertools import chain\n",
    "\n",
    "# 1. Filtrar por tipo de transformação\n",
    "er_null = df_er.withColumn(\"value\", when(col(\"value\") == 0, None).otherwise(col(\"value\")))\n",
    "\n",
    "er_null = er_null.filter(col(\"TYPE_OF_TRANSFORMATION\") == \"EOP_RT\")\n",
    "\n",
    "# 2. Criar mapa de nomes legíveis (se quiser usar)\n",
    "indicadores_map = create_map([lit(x) for x in chain(*indicadores_nome.items())])\n",
    "\n",
    "# 3. Substituir zero por nulo\n",
    "er_null = er_null.withColumn(\"value\", when(col(\"value\") == 0, None).otherwise(col(\"value\")))\n",
    "\n",
    "# 4. Criar chave de pivot — pode usar nome legível ou o código\n",
    "# Se quiser nome legível:\n",
    "# er_null = er_null.withColumn(\"INDICATOR_NOME\", indicadores_map[col(\"INDICATOR\")])\n",
    "#          .withColumn(\"pivot_key\", col(\"INDICATOR_NOME\"))\n",
    "\n",
    "# Se quiser manter como está no código original (com nome técnico):\n",
    "er_null = er_null.withColumn(\"pivot_key\", concat_ws(\"/ER/\", col(\"INDICATOR\")))\n",
    "\n",
    "# 5. Aplicar pivot\n",
    "pivoted_ER = er_null.groupBy(\"COUNTRY\", \"TYPE_OF_TRANSFORMATION\", \"TIME_PERIOD\", \"FREQUENCY\") \\\n",
    "    .pivot(\"pivot_key\") \\\n",
    "    .agg(first(\"value\"))\n",
    "\n",
    "pivoted_ER.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63d65b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1156:============================>                           (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+---------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+\n",
      "|COUNTRY|UNIT|FREQUENCY|TIME_PERIOD|           D/IIP/A_P|           D/IIP/L_P|        D_F5/IIP/A_P|        D_F5/IIP/L_P|        D_FL/IIP/A_P|        D_FL/IIP/L_P|    NIIP/IIP/NETAL_P|       O_F12/IIP/L_P|     O_F2_NV/IIP/A_P|     O_F2_NV/IIP/L_P|     O_F4_NV/IIP/A_P|     O_F4_NV/IIP/L_P|       O_F81/IIP/A_P|       O_F81/IIP/L_P|       O_FL1/IIP/A_P|     P_F3_MV/IIP/A_P|     P_F3_MV/IIP/L_P|     P_F5_MV/IIP/A_P|     P_F5_MV/IIP/L_P|        P_MV/IIP/A_P|        P_MV/IIP/L_P|           R/IIP/A_P|    R_F11_MV/IIP/A_P|    R_F12_MV/IIP/A_P|    R_FK_MV/IIP/A_P|      TA_AFR/IIP/A_P|      TL_AFR/IIP/L_P|\n",
      "+-------+----+---------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+\n",
      "|    BRA| USD|        Q|    2021-Q2|  4.6213639670572E11| 8.18234901935813E11|  4.2601196915651E11| 5.67969551999873E11|   3.612442754921E10|  2.5026534993594E11|-6.34694023801143E11|     4.11812781243E9|   3.730744947569E10|      6.7176638345E8|   1.238637526476E10|  2.0861506421037E11|   1.082809341143E10|     4.11530014445E9|   7.497987249394E10|     8.83719938002E9| 1.83386640771879E11|   4.193984129121E10| 3.61637283538907E11|   5.077704067123E10| 5.45023924310787E11| 3.52486050404625E11|     6.87302747482E9|   4.2725569499504E9|  4.4353253296664E9|9.463352608443812E11|1.581029208571842E12|\n",
      "|    THA| USD|        Q|    2021-Q3|        1.6998938E11|        2.8611294E11|         9.841339E10|        2.6385152E11|         7.157599E10|         2.226142E10|          5.21074E10|                NULL|          4.44374E10|           5.20396E9|         1.848387E10|         8.297394E10|         2.628347E10|         2.205569E10|         9.574623E10|         2.278845E10|         4.874429E10|         6.647873E10|          9.51737E10|         8.926717E10|          1.43918E11|        2.4467055E11|         1.378843E10|           5.74149E9|          1.25069E9|6.043660276055386E11|5.579733171226338E11|\n",
      "|    PRT| USD|        Q|    2021-Q3|9.337652969999995E10|2.133581276999999E11|7.103716499999995E10|1.549687043999999E11|2.234052259999999E10|5.838942329999997E10|-2.35243595599999...| 3.919491499999998E9|9.367758369999995E10|1.831693588999999E11|1.419585399999999E10|9.558232919999995E10| 8.004562699999996E9|1.044657379999999E10|1.180421154999999E11|1.313637549999999E11|1.213120250999999E11|6.087427669999997E10|4.018607739999998E10|1.922380316999999E11|1.614992603999999E11|3.283109659999998E10|2.122430699999999E10| 3.642753399999998E9|6.565292999999996E8|4.440297987971454E11|6.792736535425037E11|\n",
      "|    ESP| USD|        Q|    2012-Q4|7.450994843999999E11|7.663695317999999E11|6.129404639999999E11|4.933487285999999E11|      1.321590204E11|      2.730194838E11|     -1.209282876E12| 4.348742399999999E9|      3.280727682E11|8.817893243999999E11|      1.146980808E11|      2.664488718E11|                NULL|                NULL|5.285041415999999E11|      3.054199896E11|8.067458105999999E11|      1.404356166E11|      2.361356568E11|4.458556061999999E11|     1.0428814674E12|5.059503179999999E10|       1.50649092E10|         4.1323608E9|        3.1823928E9|1.999037867276998E12|3.208323912939587E12|\n",
      "|    FIN| USD|        Q|    2025-Q1|2.139077219999999E11|1.489452614999999E11|1.571852099999999E11|8.146939499999995E10|5.672143049999997E10|6.747586649999996E10|5.799543749999997E10| 4.649368499999997E9|1.218937019999999E11|1.478269904999999E11|5.969988149999997E10|5.041412249999997E10| 8.104760999999995E9| 7.209278999999996E9|2.090961284999999E11|1.724257079999999E11|3.502059224999998E11|3.848625899999998E11|2.076112289999999E11|5.572882979999998E11|5.578171514999998E11|1.954162349999999E10| 4.389808499999997E9| 4.778066999999997E9|7.862504999999995E8|1.040694532466015E12|9.826995011966423E11|\n",
      "|    PRT| USD|        Q|    2016-Q2|8.891480780000005E10|1.611499708000001E11|7.016019920000003E10|1.150378138000001E11|1.875571880000001E10|4.611215700000002E10|-2.30742857800000...| 1.126853000000001E9|8.709185940000005E10|1.565404204000001E11|1.262519440000001E10|1.101407216000001E11|1.086219680000001E10| 7.994550200000004E9|1.157461214000001E11|8.648791060000005E10|1.062639032000001E11|2.949468340000001E10|3.294296460000002E10|1.159837042000001E11|1.392057576000001E11|2.274688780000001E10|1.621003020000001E10| 7.482748000000004E8|6.505772000000004E8|3.537843828377108E11|5.844132767971344E11|\n",
      "|    DEU| USD|        Q|    2023-Q2|3.116161259400001E12|     2.1891849726E12|2.329773627000001E12|9.317051700000002E11|7.863876324000002E11|     1.2574798026E12|3.008816045400001E12|5.001511140000001E10|2.756742231000001E12|      2.295654387E12|9.022626564000002E11|5.215234494000001E11|      1.437180624E11|       1.73079081E11|3.935828190000001E12|     2.1143464842E12|     2.0823254688E12|      2.125395033E12|     1.2757542414E12|4.239741517200001E12|3.358079710200001E12|3.051390120000001E11|      2.053576206E11|5.282831880000001E10|      1.00966872E10|1.374742145216512E13| 1.07386115207036E13|\n",
      "|    BRA| USD|        Q|    2006-Q4|      1.139251208E11| 2.20620858063297E11|       9.74646527E10| 1.93837562259637E11|       1.64604681E10|   2.678329580366E10|-3.49896590531053E11|                NULL|       1.71995657E10|  7.60474952901248E8|       1.06704725E10|  6.6785681497722E10|  4.60486078558053E9|     4.80089536765E9|3.813878658558053E10|       1.06753778E10| 1.12728477163815E11|         3.7536468E9| 1.91513318871969E11|       1.44290246E10| 3.04241796035784E11| 8.58388644011278E10|    6.826809433375E8|        8371111.9436|               NULL|2.535173381033223E11|6.039535124506919E11|\n",
      "|    PER| USD|        Q|    2020-Q3| 1.38843521629317E10| 1.16355530613472E11|  9.73357200405976E9| 9.96269259106667E10|  4.15078015887196E9|  1.6728604702805E10|-7.70973415750862E10|         8.5775749E8| 1.58175928245754E10|                NULL|  5.70118149911036E8| 3.45661727513858E10|                NULL|                NULL| 1.63877109744865E10|  9.65140881523566E7| 5.15069387473301E10| 3.95815287870896E10| 1.61149372215588E10| 3.96780428752419E10| 6.76218759688889E10|     7.2427600788E10|       2.102188904E9|      7.2915245034E8|     4.4961355538E8|1.423688982228511E11|2.194757607791363E11|\n",
      "|    CHE| USD|        Q|    2022-Q2|2.076734800224014E12|1.795230901198232E12|1.406789271662352E12|  1.0848245952948E12|6.699455285616627E11| 7.10406305903431E11|8.054679158682924E11|1.175430913824422E10|5.002861673520707E11|9.903352261156158E11|4.188924436944355E11|3.207744479490415E11|4.047143197691807E10|3.698385729394109E10|9.596500430234237E11|6.339511708097448E11|1.656226835133075E11| 8.92476722740477E11|1.290742027820969E12|1.526427893550225E12|1.456364711334279E12|9.621305462097572E11|6.076216595006801E10|1.200687060766977E10|2.286795248990269E9|5.734601442662619E12|4.929146439506621E12|\n",
      "|    BEL| USD|        Q|    2016-Q3|1.108835305100001E12|1.096015780500001E12|5.852984654000002E11|7.279885021000004E11|5.235379558000003E11|3.680272784000002E11|1.971255820000001E11| 6.032520500000004E9|3.467901276000002E11|3.395644962000002E11|1.115954907000001E11|8.608702520000005E10|3.653888180000002E10|2.925632930000002E10|5.551849713000002E11|4.135987575000002E11|4.549513786000003E11|3.336067544000002E11|2.145177683000001E11|7.472055119000004E11|6.694680308000004E11|2.535890810000001E10| 9.676587000000006E9| 5.361744400000003E9|1.281282800000001E9|2.465232792903937E12|2.268106998629678E12|\n",
      "|    PRT| USD|        Q|    2010-Q4|       9.25665912E10|      1.421636628E11|       6.89118426E10|      1.141822986E11|       2.36547486E10|       2.79813642E10|     -2.573881974E11|         1.2480108E9|       5.50153626E10|      2.666881494E11|       9.33148632E10|        3.5649816E10|       1.27126068E10|       1.25910126E10|        1.6395174E11|       1.49600952E11|      1.954366206E11|        3.6391407E10|       6.81943032E10|      1.859910228E11|      2.636309238E11|       2.10010554E10|       1.73425398E10|         1.2880968E9|         3.567654E8|4.782056012624983E11|7.355921347348972E11|\n",
      "|    DEU| USD|        Q|    2021-Q3|3.086127711999998E12|2.184858878499999E12|2.357058292799999E12|8.878858252999996E11|7.290694191999996E11|1.296973053199999E12|2.799711883799999E12|5.297624079999997E10|2.784044338899999E12|2.331755861999999E12|9.086458143999995E11|4.461400278999998E11|1.369645172999999E11|1.545507024999999E11|3.958383045199998E12|2.534540046899999E12|2.413094863299999E12|2.100092493199999E12|1.517478897599999E12|4.634632540099998E12|3.930573760899998E12|2.858947731999999E11|1.863558996999999E11|5.280718739999997E10|9.572359299999994E9|1.302945043764389E13|1.022974303853671E13|\n",
      "|    AUS| USD|        Q|    2020-Q4|6.475510414000018E11|8.313762158000024E11|5.943810546000017E11|6.247200028000018E11|5.316998680000015E10|2.066562130000006E11|-8.09755161400002...| 4.440973200000013E9|7.711550480000021E10|1.838505910000005E11|2.141248424000006E11|1.962238540000006E11|2.387542980000007E10|  7.04733000000002E9| 3.53558769600001E11|2.870466082000008E11|1.044499028000003E12| 6.92135608800002E11|5.280691452000015E11|9.791822170000028E11|1.572567403000004E12|4.588389480000013E10| 4.000418800000011E9| 4.491806400000013E9|2.531647400000007E9|2.362556693664997E12| 3.17231093379697E12|\n",
      "|    USA| USD|        Q|    2012-Q2|         5.413818E12|         4.490546E12|         4.449252E12|         3.243648E12|          9.64566E11|         1.246898E12|        -5.259919E12|           5.3593E10|          2.04729E12|          2.52954E12|          2.17885E12|         2.173593E12|           5.3917E10|          1.34291E11|         4.280057E12|          2.37244E12|         9.035671E12|         4.673015E12|         4.261853E12|         7.045455E12|        1.3297524E13|           5.5662E11|          4.18006E11|           5.4341E10|           3.393E10|2.150739945741307E13|2.676731921961794E13|\n",
      "|    AUS| USD|        Q|    2017-Q1|5.198814347999999E11|6.992570675999998E11|4.677814595999999E11|4.807793171999999E11|5.209997519999999E10|2.184777503999999E11|-7.78806646799999...| 4.192733999999999E9|6.106027199999998E10|1.965295331999999E11|2.261492687999999E11|      1.583011248E11|       1.74718908E10| 5.270537999999999E9|3.318925427999999E11|2.527328075999999E11|8.643598235999998E11|4.551566291999999E11|4.229035355999999E11|7.078894367999998E11|     1.2872633592E12|6.112601039999998E10| 3.195956399999999E9| 3.880858799999999E9|6.153419999999998E8| 1.75109777952514E12|2.529904702931625E12|\n",
      "|    USA| USD|        Q|    2010-Q4|         5.486391E12|         4.099097E12|          4.62085E12|         2.927753E12|          8.65541E11|         1.171344E12|        -2.511072E12|           5.4387E10|         2.767247E12|         2.364754E12| 2.11045524127942E12|          2.23843E12|           5.1078E10|          1.11758E11|          4.92878E12|          2.26012E12|         8.323493E12|         4.900246E12|         3.545769E12|         7.160366E12|        1.1869262E13|          4.88673E11|          3.67537E11|           5.6824E10|          1.2492E10|2.176854761880136E13|2.427961937543121E13|\n",
      "|    POL| USD|        Q|    2023-Q2|           9.3163E10|          3.78086E11|           2.9749E10|          2.50792E11|           6.3414E10|          1.27294E11|          -2.6425E11|             6.912E9|           3.6696E10|           3.6584E10|           2.3762E10|          1.14381E11|           2.5794E10|           2.7129E10|          1.08626E11|           2.8236E10|           9.0043E10|           2.0046E10|           4.2163E10|           4.8282E10|          1.32206E11|          1.80763E11|           1.6957E10|             5.601E9|            1.506E9|4.467584487628984E11| 7.11007147998638E11|\n",
      "|    HUN| USD|        Q|    2003-Q2| 6.933720168194695E9|3.953682247403211E10| 3.724650290952013E9|3.137681818181818E10| 3.209069877242682E9| 8.160004292213924E9|-5.23495575081380...|                NULL|  1.30224117948751E9| 9.149433856983433E9| 6.979376770538244E9| 9.868519615417631E9| 1.948272383895613E9| 4.793458665979912E7|1.049603385254528E10| 5.285543823504163E8|1.850582582195467E10| 3.975864881105674E8|  5.60703150484591E9| 9.261408704609838E8|2.411285732680058E10|1.240330886771397E10|  3.48004120525367E7|                NULL|7.315992789080608E8|3.185266121354744E10|8.416386256330157E10|\n",
      "|    SWE| USD|        Q|    2025-Q1|7.290874653587736E11|6.321071834439858E11|4.982014474549913E11|4.018059293817413E11|2.308860179037821E11|2.303012540622446E11|3.341741930338736E11| 8.696692385908249E9|2.035478597204777E11|2.571724784177682E11|1.488079430587954E11|6.240544689674422E10|1.819217656558407E10|1.886835337041689E10|                NULL|1.772678788603784E11|4.819780888011643E11| 8.34460693422653E11|3.906528500508404E11|1.011728572283031E12|8.726310385389875E11|6.701896046414259E10|1.262545606794665E10| 9.004127041090975E9|1.420240445002692E9|2.300999019944179E12|1.966806694430817E12|\n",
      "+-------+----+---------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, concat_ws, lit, create_map, first\n",
    "from itertools import chain\n",
    "\n",
    "# Substitui 0 por nulo\n",
    "iip_null = df_iip.withColumn(\"value\", when(col(\"value\") == 0, None).otherwise(col(\"value\")))\n",
    "\n",
    "\n",
    "# Adiciona colunas de nomes e chave para pivot\n",
    "iip_null = iip_null \\\n",
    "    .withColumn(\"pivot_key\", concat_ws(\"/IIP/\", col(\"INDICATOR\"), col(\"BOP_ACCOUNTING_ENTRY\")))\n",
    "\n",
    "# Pivot final\n",
    "pivoted_IIP = iip_null.groupBy(\"COUNTRY\", \"UNIT\", \"FREQUENCY\", \"TIME_PERIOD\") \\\n",
    "    .pivot(\"pivot_key\") \\\n",
    "    .agg(first(\"value\"))\n",
    "\n",
    "pivoted_IIP.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "428a97af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----------+---------+----------------------------+----------------------------+----------------------------+----------------------------+------------------------------------+----------------------------+-------------------------------+-----------------------------------------+----------------------------------------+-------------------------------------+--------------------------------------+------------------------------------+-------------------------------------+------------------------------------+---------------------------------+----------------------------------------+---------------------------------------+------------------------------------+--------------------+-------------------------------------+-------------------------------------+----------------------------+-----------------------------+-------------------------------+\n",
      "|COUNTRY|  SECTOR|TIME_PERIOD|FREQUENCY|IRFCLDT1_IRFCL32_USD_IRFCL13|IRFCLDT1_IRFCL54_USD_IRFCL13|IRFCLDT1_IRFCL56_USD_IRFCL13|IRFCLDT1_IRFCL57_USD_IRFCL13|IRFCLDT1_IRFCL65_DIC_XDR_USD_IRFCL13|IRFCLDT1_IRFCL65_USD_IRFCL13|IRFCLDT1_IRFCLCDCFC_USD_IRFCL13|IRFCLDT2_IRFCL151_SM1MUT3M_FO_USD_IRFCL13|IRFCLDT2_IRFCL151_SM3MUTY_FO_USD_IRFCL13|IRFCLDT2_IRFCL151_SUTM_FO_USD_IRFCL13|IRFCLDT2_IRFCL1_SUTM_IN_LP_USD_IRFCL13|IRFCLDT2_IRFCL1_SUTM_SHP_USD_IRFCL13|IRFCLDT2_IRFCL24_SM1MUT3M_USD_IRFCL13|IRFCLDT2_IRFCL24_SM3MUTY_USD_IRFCL13|IRFCLDT2_IRFCL24_SUTM_USD_IRFCL13|IRFCLDT2_IRFCL26_SM1MUT3M_FO_USD_IRFCL13|IRFCLDT2_IRFCL26_SM3MUTY_FO_USD_IRFCL13|IRFCLDT2_IRFCL26_SUTM_FO_USD_IRFCL13|IRFCLDT2_USD_IRFCL13|IRFCLDT4_IRFCL11_DIC_XDRB_USD_IRFCL13|IRFCLDT4_IRFCL11_DIC_XXDR_USD_IRFCL13|IRFCLDT4_IRFCL68_USD_IRFCL13|IRFCLDT4_IRFCL69X_USD_IRFCL13|IRFCLDT4_IRFCLU97_A_USD_IRFCL13|\n",
      "+-------+--------+-----------+---------+----------------------------+----------------------------+----------------------------+----------------------------+------------------------------------+----------------------------+-------------------------------+-----------------------------------------+----------------------------------------+-------------------------------------+--------------------------------------+------------------------------------+-------------------------------------+------------------------------------+---------------------------------+----------------------------------------+---------------------------------------+------------------------------------+--------------------+-------------------------------------+-------------------------------------+----------------------------+-----------------------------+-------------------------------+\n",
      "|    GBR|S1XS1311|    2010-Q2|        Q|                   4.4121E10|                   9.7423E10|                   1.2409E10|                     4.077E9|                           1.3531E10|                   9.6968E10|                      4.4915E10|                                   -5.4E7|                                 -2.18E8|                               -3.1E7|                               2.112E9|                            -4.101E9|                             -4.916E9|                            -7.059E9|                         -6.789E9|                                -4.862E9|                               -6.841E9|                            -6.758E9|          -3.2374E10|                            9.0355E10|                              6.614E9|                   1.5305E10|                     2.223E10|                         3.46E8|\n",
      "|    FRA|S1XS1311|    2005-Q3|        Q|        2.242099980000001E10|        8.124496560000002E10|        4.397858820000001E10|         3.788413200000001E9|                 8.766576000000004E8|        7.452673380000002E10|           2.588307480000001E10|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|-2.265100200000001E9|                 7.452657780200218E10|                                 NULL|        -3.010500000000001E8|          1.964050200000001E9|                           NULL|\n",
      "|    CAN|S1XS1311|    2020-Q4|        Q|                   7.5172E10|                   9.0428E10|                        NULL|                     4.722E9|                             8.886E9|                   9.0428E10|                       7.682E10|                                  -1.13E8|                                 -5.37E8|                               -9.6E7|                                  NULL|                                NULL|                             -3.633E9|                            -5.601E9|                         -3.919E9|                                 -3.52E9|                               -5.064E9|                            -3.823E9|          -1.3153E10|                            9.0428E10|                                 NULL|                      9.46E8|                         NULL|                        -2.33E9|\n",
      "|    SWE|S1XS1311|    2014-Q3|        Q|                    4.969E10|                   6.3677E10|                     4.894E9|                      1.64E9|                             3.113E9|                   6.3648E10|                      5.4001E10|                                   -4.1E7|                                 -1.87E8|                               -1.0E7|                             1.5885E10|                          -1.5625E10|                             -3.952E9|                          -1.2614E10|                         -2.716E9|                                -3.911E9|                             -1.2427E10|                            -2.706E9|          -1.7829E10|                            5.9115E10|                              4.533E9|                        NULL|                         NULL|                       -9.835E9|\n",
      "|    FIN|S1XS1311|    2008-Q2|        Q|         6.469545600000005E9|        1.182772920000001E10|         1.470781200000001E9|         1.544872000000001E8|                 2.522240000000002E8|         8.608720400000008E9|            6.728075200000005E9|                     -2.522240000000002E7|                    -1.544872000000001E8|                                 NULL|                                  NULL|                -1.216980800000001E9|                 -2.522240000000002E7|                -1.752956800000001E9|                             NULL|                                    NULL|                   -1.600046000000001E9|                                NULL|-1.237474000000001E9|                  8.574039600000007E9|                  3.625720000000003E7|                        NULL|                         NULL|            7.582484000000006E8|\n",
      "|    AUS|S1XS1311|    2023-Q1|        Q|        2.611169360000008E10|        5.869979600000019E10|         4.637992000000015E9|         2.629761600000008E9|                1.297832320000004E10|        5.875886160000019E10|           3.637434160000011E10|                                     NULL|                                    NULL|                                 NULL|                   4.040624000000013E8|                 -3.14121600000001E8|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|  9.59816000000003E8|                 5.443096400000017E10|                  4.327897600000014E9|          9.55788800000003E8|          4.795724000000015E9|           -3.597632000000011E8|\n",
      "|    ESP|S1XS1311|    2021-Q2|        Q|        4.317176483768907E10|        8.567977627705011E10|        1.593958250753506E10|          3.39199378282844E9|                 3.646958797740448E9|        7.946333967485037E10|           5.590203366318586E10|                                     NULL|                    -3.484403926985103E7|                                 NULL|                                  NULL|                                NULL|                    902834.1711533664|                -3.484403926985103E7|                   -1059055.78496|                                    NULL|                                   NULL|                          -1059537.8| -1.46987307915935E7|                 7.235203840742099E10|                  7.111301267428192E9|                        NULL|                         NULL|              3.3755655817606E8|\n",
      "|    AUS|S1XS1311|    2013-Q2|        Q|        3.155808005664316E10|        4.806222553052345E10|         3.058342290944206E9|         2.456325104053662E9|                 4.397829253652228E9|        4.806761846336904E10|            3.77221266681395E10|                                     NULL|                                    NULL|                                 NULL|                   4.233653935499294E7|                -3.961746440030049E9|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|-3.925004668657951E9|                 4.601644034218228E10|                  2.051178121186682E9|         5.076548290506341E9|           7.20942819999999E9|             -5392932.845590655|\n",
      "|    DNK|S1XS1311|    2015-Q1|        Q|        7.661892347357655E10|        1.099118426695478E11|         2.536462759445173E9|         8.201276160571536E8|                 1.964192605182422E9|        1.090214638111786E11|           8.278544149368689E10|                                     NULL|                                    NULL|                   -464876.7770463941|                   9.966497184092644E7|                  -3823728.520604376|                  -1.61233108156769E9|                -3.039287741080559E9|             -1.310610598182263E9|                    -1.616706468664929E9|                   -3.089572644648336E9|                -1.314521108502456E9|-6.029762081034755E9|                 1.084480653652383E11|                  5.733984459403402E8|        2.183018782318118E10|         2.183018782318118E10|           -1.303669342663517E9|\n",
      "|    USA|S1XS1311|    2022-Q2|        Q|                     9.732E9|         2.38690845416557E11|           1.104105882109E10|         3.35879749621915E10|                 1.58104811633276E11|         2.38690845416557E11|                      3.5957E10|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                             -1.84E8|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|             -1.84E8|                  2.38690845416557E11|                                 NULL|                        NULL|                         NULL|                           NULL|\n",
      "|    FRA|S1XS1311|    2024-Q2|        Q|        2.854725258699999E10|        2.655973102839999E11|        1.828353431109999E11|         6.772977494499998E9|                3.658102751399999E10|        2.611699792039999E11|           2.873328300649999E10|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|-3.885957819999999E8|                 2.524188065609999E11|                  8.751172642999996E9|        -3.790694024999999E8|            9525308.999999996|                           NULL|\n",
      "|    JPN|S1XS1311|    2024-Q3|        Q|                  9.38409E11|                 1.294615E12|                   7.1533E10|                   1.0841E10|                           5.9593E10|                 1.254898E12|                    1.097895E12|                                     NULL|                                    NULL|                                 NULL|                                 5.0E9|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|              2.0E10|                                 NULL|                                 NULL|                     4.641E9|                   1.73722E11|                         -6.8E8|\n",
      "|    IRL|S1XS1311|    2007-Q1|        Q|         5.030554867999997E8|         9.385460959999994E8|         1.281164963999999E8|         9.175302919999994E7|                 9.709088359999993E7|         8.856469999999994E8|            5.686785999999996E8|                                     NULL|                      -9588959.999999994|                   -7191719.999999995|                   1.787275599999999E8|                  -1065439.999999999|                                 NULL|                  -9588959.999999994|               -7191719.999999995|                                    NULL|                                   NULL|                                NULL| 1.608814399999999E8|                  8.854831885999994E8|                                 NULL|                        NULL|                         NULL|                           NULL|\n",
      "|    ROU|S1XS1311|    2009-Q3|        Q|        3.211984426841998E10|        4.483046964473998E10|         3.333143918159998E9|                        NULL|                 1.472587937999999E9|        4.483046964473998E10|           4.002473778857998E10|                     -1.241433539999999E8|                    -7.804865429999996E8|                 -5.684412599999997E7|                                  NULL|                                NULL|                 -2.772359189999999E8|                -2.543313383999999E9|             -1.271012399999999E8|                    -1.530925649999999E8|                   -1.762826840999999E9|                -7.025711399999996E7|-2.947650542999998E9|                 4.480271369180998E10|                  2.776034582999969E7|                        NULL|                         NULL|                           NULL|\n",
      "|    CHL|S1XS1311|    2010-Q3|        Q|           2.062669201322E10|         4.48309219297702E10|               1.038072809E7|               2.850657025E8|                     1.22978906334E9|           2.644553322233E10|              2.491546022179E10|                           -5.014109968E7|                               -1.3872E8|                            -726000.0|                                  NULL|                                NULL|                       -8.840187024E7|                           -2.1713E8|                  -4.7944628113E8|                          -3.826077056E7|                               -7.841E7|                     -4.7872028113E8|     -8.1077631854E8|                  2.46792416385681E10|                   1.76629158376191E9|           5.4574507623299E8|           5.62304927793299E9|                           NULL|\n",
      "|    MYS|S1XS1311|    2003-Q2|        Q|                  2.98044E10|                  3.70873E10|                     2.946E8|                     9.773E8|                             1.622E8|                  3.63027E10|                     3.29083E10|                                   -3.2E7|                                 -3.89E8|                               -8.4E7|                                  NULL|                          -4000000.0|                              -1.18E8|                            -2.081E9|                          -1.08E8|                                  -8.6E7|                               -1.692E9|                              -2.4E7|            -2.311E9|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|\n",
      "|    RUS|S1XS1311|    2013-Q1|        Q|          3.9562776031062E11|          5.2844872322426E11|              5.044094592E10|             4.61409423537E9|                     8.52762271391E9|          5.2770816720139E11|             4.6162102316015E11|                                -1.6844E8|                              -2.00771E9|                            -2.8776E8|                                  NULL|                    -5.92069990831E9|                            -2.2567E7|                         -2.465442E9|              -3.80963703409357E9|                               -1.3446E8|                             -1.81026E9|                 -3.59054303409357E9|-1.22183459424035...|                   5.1209895073367E11|                  1.56092164677202E10|            -4.51548912562E9|          1.02128378680032E10|                           NULL|\n",
      "|    ARG|S1XS1311|    2006-Q4|        Q|                 1.514092E10|                 3.203682E10|                   1.11451E9|                    290000.0|                            4.8538E8|                 3.203682E10|                    3.031904E10|                                -7.1622E8|                                -1.613E9|                              -2.47E8|                                  NULL|                                NULL|                           -1.50628E9|                             -5.69E9|                       -3.08033E9|                               -7.9006E8|                               -4.077E9|                          -2.83333E9|        -1.027661E10|                          3.203636E10|                            1460000.0|                        NULL|                      1.019E8|                      8020000.0|\n",
      "|    PHL|S1XS1311|    2008-Q1|        Q|                 2.345657E10|                 3.680049E10|                   3.83439E9|                    1.4406E8|                             80000.0|                 3.662401E10|                    3.219697E10|                                -1.3965E8|                              -2.19844E9|                            -1.0815E8|                              2.9105E9|                                NULL|                            -4.8652E8|                          -4.17225E9|                       -1.41998E9|                               -3.4687E8|                             -1.97381E9|                          -1.31183E9|           5.25575E9|                          3.649199E10|                             1.3202E8|                  -9.52353E9|                         NULL|                     -5790000.0|\n",
      "|    ARG|S1XS1311|    2014-Q4|        Q|           8.6543302580449E8|         3.14075490693067E10|           2.3547846483384E9|            283133.693872778|                   2.9748033070311E9|         3.14075490693067E10|              2.593836341723E10|                          -3.7434877123E8|                        -4.26181831221E9|                       -3.707184435E7|                                  NULL|                                NULL|                       -1.017796691E9|                    -1.3189186518E10|             -1.20226085098504E10|                         -6.4344791977E8|                       -8.92736820579E9|                -1.19855366655004E10|-2.99599000854777...|                  2.84527186934857E10|                   2.95482839281034E9|                     -9.97E7|                         NULL|                           NULL|\n",
      "+-------+--------+-----------+---------+----------------------------+----------------------------+----------------------------+----------------------------+------------------------------------+----------------------------+-------------------------------+-----------------------------------------+----------------------------------------+-------------------------------------+--------------------------------------+------------------------------------+-------------------------------------+------------------------------------+---------------------------------+----------------------------------------+---------------------------------------+------------------------------------+--------------------+-------------------------------------+-------------------------------------+----------------------------+-----------------------------+-------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, concat_ws, lit, create_map, first\n",
    "from itertools import chain\n",
    "\n",
    "# 1. Filtrar por tipo de transformação\n",
    "irfcl_null = df_irfcl.withColumn(\"value\", when(col(\"value\") == 0, None).otherwise(col(\"value\")))\n",
    "irfcl_null = irfcl_null.filter(col(\"SECTOR\") == \"S1XS1311\")\n",
    "\n",
    "# Se quiser manter como está no código original (com nome técnico):\n",
    "irfcl_null = irfcl_null.withColumn(\"pivot_key\",  col(\"INDICATOR\"))\n",
    "\n",
    "# 5. Aplicar pivot\n",
    "pivoted_IRFCL = irfcl_null.groupBy(\"COUNTRY\", \"SECTOR\", \"TIME_PERIOD\", \"FREQUENCY\") \\\n",
    "    .pivot(\"pivot_key\") \\\n",
    "    .agg(first(\"value\"))\n",
    "\n",
    "pivoted_IRFCL.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bdcb71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "29480549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-----+\n",
      "|COUNTRY|TIME_PERIOD|count|\n",
      "+-------+-----------+-----+\n",
      "|    NLD|    2022-Q2|    1|\n",
      "|    FRA|    2008-Q3|    1|\n",
      "|    JPN|    2019-Q2|    1|\n",
      "|    GBR|    2022-Q1|    1|\n",
      "|    GBR|    2012-Q2|    1|\n",
      "|    AUS|    2023-Q4|    1|\n",
      "|    CHE|    2015-Q2|    1|\n",
      "|    BEL|    2009-Q2|    1|\n",
      "|    KOR|    2009-Q3|    1|\n",
      "|    NOR|    2008-Q4|    1|\n",
      "|    BRA|    2005-Q1|    1|\n",
      "|    MEX|    2001-Q3|    1|\n",
      "|    NOR|    2016-Q4|    1|\n",
      "|    SGP|    2020-Q2|    1|\n",
      "|    SGP|    2023-Q4|    1|\n",
      "|    EGY|    2023-Q4|    1|\n",
      "|    COL|    2004-Q3|    1|\n",
      "|    HKG|    2012-Q2|    1|\n",
      "|    EGY|    2022-Q1|    1|\n",
      "|    ROU|    2024-Q2|    1|\n",
      "+-------+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exemplo: contar registros por país\n",
    "count = pivoted_IRFCL.groupBy([\"COUNTRY\", \"TIME_PERIOD\"]).count()\n",
    "# Para ordenar por contagem decrescente:\n",
    "count_sorted = count.orderBy(\"count\", ascending=False)\n",
    "count_sorted.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e5c77e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Só há uma linha distinta.\n",
      "+-------+--------+-----------+---------+----------------------------+----------------------------+----------------------------+----------------------------+------------------------------------+----------------------------+-------------------------------+-----------------------------------------+----------------------------------------+-------------------------------------+--------------------------------------+------------------------------------+-------------------------------------+------------------------------------+---------------------------------+----------------------------------------+---------------------------------------+------------------------------------+--------------------+-------------------------------------+-------------------------------------+----------------------------+-----------------------------+-------------------------------+\n",
      "|COUNTRY|  SECTOR|TIME_PERIOD|FREQUENCY|IRFCLDT1_IRFCL32_USD_IRFCL13|IRFCLDT1_IRFCL54_USD_IRFCL13|IRFCLDT1_IRFCL56_USD_IRFCL13|IRFCLDT1_IRFCL57_USD_IRFCL13|IRFCLDT1_IRFCL65_DIC_XDR_USD_IRFCL13|IRFCLDT1_IRFCL65_USD_IRFCL13|IRFCLDT1_IRFCLCDCFC_USD_IRFCL13|IRFCLDT2_IRFCL151_SM1MUT3M_FO_USD_IRFCL13|IRFCLDT2_IRFCL151_SM3MUTY_FO_USD_IRFCL13|IRFCLDT2_IRFCL151_SUTM_FO_USD_IRFCL13|IRFCLDT2_IRFCL1_SUTM_IN_LP_USD_IRFCL13|IRFCLDT2_IRFCL1_SUTM_SHP_USD_IRFCL13|IRFCLDT2_IRFCL24_SM1MUT3M_USD_IRFCL13|IRFCLDT2_IRFCL24_SM3MUTY_USD_IRFCL13|IRFCLDT2_IRFCL24_SUTM_USD_IRFCL13|IRFCLDT2_IRFCL26_SM1MUT3M_FO_USD_IRFCL13|IRFCLDT2_IRFCL26_SM3MUTY_FO_USD_IRFCL13|IRFCLDT2_IRFCL26_SUTM_FO_USD_IRFCL13|IRFCLDT2_USD_IRFCL13|IRFCLDT4_IRFCL11_DIC_XDRB_USD_IRFCL13|IRFCLDT4_IRFCL11_DIC_XXDR_USD_IRFCL13|IRFCLDT4_IRFCL68_USD_IRFCL13|IRFCLDT4_IRFCL69X_USD_IRFCL13|IRFCLDT4_IRFCLU97_A_USD_IRFCL13|\n",
      "+-------+--------+-----------+---------+----------------------------+----------------------------+----------------------------+----------------------------+------------------------------------+----------------------------+-------------------------------+-----------------------------------------+----------------------------------------+-------------------------------------+--------------------------------------+------------------------------------+-------------------------------------+------------------------------------+---------------------------------+----------------------------------------+---------------------------------------+------------------------------------+--------------------+-------------------------------------+-------------------------------------+----------------------------+-----------------------------+-------------------------------+\n",
      "|    ESP|S1XS1311|    2016-Q4|        Q|        4.490784171029396E10|        6.849672042001608E10|         1.04792649485381E10|         1.759567786106349E9|                 3.742913407092761E9|        6.314254998698866E10|           4.687976716505064E10|                     -7.999999999999996E7|                    -4.114758088643836E7|                                 NULL|                                  NULL|                -1.601054666665822E9|                 -7.920646514696132E7|                -3.828331562511055E8|               -783064.0381237891|                                    NULL|                   -3.416855753646674E8|                  -1013397.839999999|-1.613971441697678E9|                 5.677354449590842E10|                  6.369005491075561E9|                        NULL|                         NULL|             7.88816263106127E8|\n",
      "+-------+--------+-----------+---------+----------------------------+----------------------------+----------------------------+----------------------------+------------------------------------+----------------------------+-------------------------------+-----------------------------------------+----------------------------------------+-------------------------------------+--------------------------------------+------------------------------------+-------------------------------------+------------------------------------+---------------------------------+----------------------------------------+---------------------------------------+------------------------------------+--------------------+-------------------------------------+-------------------------------------+----------------------------+-----------------------------+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linha = pivoted_IRFCL.where((pivoted_IRFCL.COUNTRY == \"ESP\") & (pivoted_IRFCL.TIME_PERIOD == \"2016-Q4\"))\n",
    "# Verifique se há mais de uma linha distinta\n",
    "if linha.count() > 1:\n",
    "    # Para cada coluna, veja quais têm valores diferentes entre as linhas\n",
    "    cols = linha.columns\n",
    "    vals = linha.collect()\n",
    "    diffs = []\n",
    "    for c in cols:\n",
    "        vset = set([row[c] for row in vals])\n",
    "        if len(vset) > 1:\n",
    "            diffs.append(c)\n",
    "    print(f\"Colunas com valores distintos: {diffs}\")\n",
    "else:\n",
    "    print(\"Só há uma linha distinta.\")\n",
    "linha = linha.distinct()\n",
    "linha.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ed46e519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1208:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+----+---------+---------------+------------------+----------------+----------------+----------------+----------------+----------------+--------------+------------------+----------------------+-----------+-----------+--------------+------------+------------+---------------+------------+------------+---------------+---------------+----------------+----------------+-------------------+----------------+----------------+-------------------+-----------------+-----------------+--------------------+----------------+----------------+----------------+----------------+----------------+------------------+-----------+-----------+-----------+--------------+----------------------+---------+-----------------+-------+-----------------+----+---------+---------+---------+------------+------------+------------+------------+----------------+-------------+---------------+---------------+---------------+---------------+-------------+-------------+-------------+---------------+---------------+---------------+---------------+------------+------------+---------+----------------+----------------+---------------+--------------+--------------+------+---------+----------------------------+----------------------------+----------------------------+----------------------------+------------------------------------+----------------------------+-------------------------------+-----------------------------------------+----------------------------------------+-------------------------------------+--------------------------------------+------------------------------------+-------------------------------------+------------------------------------+---------------------------------+----------------------------------------+---------------------------------------+------------------------------------+--------------------+-------------------------------------+-------------------------------------+----------------------------+-----------------------------+-------------------------------+\n",
      "|COUNTRY|TIME_PERIOD|UNIT|FREQUENCY|CAB/BOP/NETCD_T|CABXEF/BOP/NETCD_T|DXEF/BOP/L_NIL_T|D_F5/BOP/A_NFA_T|D_F5/BOP/L_NIL_T|D_FL/BOP/A_NFA_T|D_FL/BOP/L_NIL_T|EO/BOP/NETCD_T|FAB/BOP/NNAFANIL_T|FABXRRI/BOP/NNAFANIL_T|GS/BOP/CD_T|GS/BOP/DB_T|GS/BOP/NETCD_T|IN1/BOP/CD_T|IN1/BOP/DB_T|IN1/BOP/NETCD_T|IN2/BOP/CD_T|IN2/BOP/DB_T|IN2/BOP/NETCD_T|KAB/BOP/NETCD_T|O_F2/BOP/A_NFA_T|O_F2/BOP/L_NIL_T|O_F2/BOP/NNAFANIL_T|O_F4/BOP/A_NFA_T|O_F4/BOP/L_NIL_T|O_F4/BOP/NNAFANIL_T|O_F81/BOP/A_NFA_T|O_F81/BOP/L_NIL_T|O_F81/BOP/NNAFANIL_T|PXEF/BOP/L_NIL_T|P_F3/BOP/A_NFA_T|P_F3/BOP/L_NIL_T|P_F5/BOP/A_NFA_T|P_F5/BOP/L_NIL_T|RUE/BOP/NNAFANIL_T|R_F/BOP/A_T|SF/BOP/CD_T|SF/BOP/DB_T|SF/BOP/NETCD_T|TYPE_OF_TRANSFORMATION|FREQUENCY|          XDC_EUR|XDC_USD|          XDC_XDR|UNIT|FREQUENCY|D/IIP/A_P|D/IIP/L_P|D_F5/IIP/A_P|D_F5/IIP/L_P|D_FL/IIP/A_P|D_FL/IIP/L_P|NIIP/IIP/NETAL_P|O_F12/IIP/L_P|O_F2_NV/IIP/A_P|O_F2_NV/IIP/L_P|O_F4_NV/IIP/A_P|O_F4_NV/IIP/L_P|O_F81/IIP/A_P|O_F81/IIP/L_P|O_FL1/IIP/A_P|P_F3_MV/IIP/A_P|P_F3_MV/IIP/L_P|P_F5_MV/IIP/A_P|P_F5_MV/IIP/L_P|P_MV/IIP/A_P|P_MV/IIP/L_P|R/IIP/A_P|R_F11_MV/IIP/A_P|R_F12_MV/IIP/A_P|R_FK_MV/IIP/A_P|TA_AFR/IIP/A_P|TL_AFR/IIP/L_P|SECTOR|FREQUENCY|IRFCLDT1_IRFCL32_USD_IRFCL13|IRFCLDT1_IRFCL54_USD_IRFCL13|IRFCLDT1_IRFCL56_USD_IRFCL13|IRFCLDT1_IRFCL57_USD_IRFCL13|IRFCLDT1_IRFCL65_DIC_XDR_USD_IRFCL13|IRFCLDT1_IRFCL65_USD_IRFCL13|IRFCLDT1_IRFCLCDCFC_USD_IRFCL13|IRFCLDT2_IRFCL151_SM1MUT3M_FO_USD_IRFCL13|IRFCLDT2_IRFCL151_SM3MUTY_FO_USD_IRFCL13|IRFCLDT2_IRFCL151_SUTM_FO_USD_IRFCL13|IRFCLDT2_IRFCL1_SUTM_IN_LP_USD_IRFCL13|IRFCLDT2_IRFCL1_SUTM_SHP_USD_IRFCL13|IRFCLDT2_IRFCL24_SM1MUT3M_USD_IRFCL13|IRFCLDT2_IRFCL24_SM3MUTY_USD_IRFCL13|IRFCLDT2_IRFCL24_SUTM_USD_IRFCL13|IRFCLDT2_IRFCL26_SM1MUT3M_FO_USD_IRFCL13|IRFCLDT2_IRFCL26_SM3MUTY_FO_USD_IRFCL13|IRFCLDT2_IRFCL26_SUTM_FO_USD_IRFCL13|IRFCLDT2_USD_IRFCL13|IRFCLDT4_IRFCL11_DIC_XDRB_USD_IRFCL13|IRFCLDT4_IRFCL11_DIC_XXDR_USD_IRFCL13|IRFCLDT4_IRFCL68_USD_IRFCL13|IRFCLDT4_IRFCL69X_USD_IRFCL13|IRFCLDT4_IRFCLU97_A_USD_IRFCL13|\n",
      "+-------+-----------+----+---------+---------------+------------------+----------------+----------------+----------------+----------------+----------------+--------------+------------------+----------------------+-----------+-----------+--------------+------------+------------+---------------+------------+------------+---------------+---------------+----------------+----------------+-------------------+----------------+----------------+-------------------+-----------------+-----------------+--------------------+----------------+----------------+----------------+----------------+----------------+------------------+-----------+-----------+-----------+--------------+----------------------+---------+-----------------+-------+-----------------+----+---------+---------+---------+------------+------------+------------+------------+----------------+-------------+---------------+---------------+---------------+---------------+-------------+-------------+-------------+---------------+---------------+---------------+---------------+------------+------------+---------+----------------+----------------+---------------+--------------+--------------+------+---------+----------------------------+----------------------------+----------------------------+----------------------------+------------------------------------+----------------------------+-------------------------------+-----------------------------------------+----------------------------------------+-------------------------------------+--------------------------------------+------------------------------------+-------------------------------------+------------------------------------+---------------------------------+----------------------------------------+---------------------------------------+------------------------------------+--------------------+-------------------------------------+-------------------------------------+----------------------------+-----------------------------+-------------------------------+\n",
      "|    ARE|    2000-Q1|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|3.508339250000001| 3.6725|4.946394418554536|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|\n",
      "|    ARE|    2000-Q2|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|3.509440999999998| 3.6725|4.911157856448429|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|\n",
      "|    ARE|    2000-Q3|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|       3.21894625| 3.6725| 4.76650300266976|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|\n",
      "|    ARE|    2000-Q4|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|       3.41726125| 3.6725|4.784929004552361|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|\n",
      "|    ARE|    2001-Q1|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|3.243552000000001| 3.6725|4.629740520220209|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|\n",
      "|    ARE|    2001-Q2|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|          3.11428| 3.6725|4.574642343313052|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|\n",
      "|    ARE|    2001-Q3|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|3.353359749999999| 3.6725|4.733884169685095|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|\n",
      "|    ARE|    2001-Q4|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|       3.23657425| 3.6725|4.615340146484423|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|\n",
      "|    ARE|    2002-Q1|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|3.203889000000001| 3.6725|4.579285544171245|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|\n",
      "|    ARE|    2002-Q2|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|3.663318750000001| 3.6725|4.886132165717381|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|\n",
      "|    ARE|    2002-Q3|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|3.621085000000002| 3.6725|4.857592195049689|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|\n",
      "|    ARE|    2002-Q4|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|       3.85135075| 3.6725|4.992848908030975|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|\n",
      "|    ARE|    2003-Q1|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|       4.00118875| 3.6725|5.045238860634635|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|\n",
      "|    ARE|    2003-Q2|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|       4.19656575| 3.6725|5.144652643139716|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|\n",
      "|    ARE|    2003-Q3|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|         4.279197| 3.6725|5.250914352546891|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|\n",
      "|    ARE|    2003-Q4|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|        4.6383675| 3.6725|5.457225604455532|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|\n",
      "|    ARE|    2004-Q1|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|         4.489264| 3.6725|5.437180394467624|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|\n",
      "|    ARE|    2004-Q2|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|       4.46392375| 3.6725|5.384699974341116|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|\n",
      "|    ARE|    2004-Q3|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|       4.55720525| 3.6725|5.394880262303561|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|\n",
      "|    ARE|    2004-Q4|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|       5.00231225| 3.6725|5.703419100746684|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|\n",
      "+-------+-----------+----+---------+---------------+------------------+----------------+----------------+----------------+----------------+----------------+--------------+------------------+----------------------+-----------+-----------+--------------+------------+------------+---------------+------------+------------+---------------+---------------+----------------+----------------+-------------------+----------------+----------------+-------------------+-----------------+-----------------+--------------------+----------------+----------------+----------------+----------------+----------------+------------------+-----------+-----------+-----------+--------------+----------------------+---------+-----------------+-------+-----------------+----+---------+---------+---------+------------+------------+------------+------------+----------------+-------------+---------------+---------------+---------------+---------------+-------------+-------------+-------------+---------------+---------------+---------------+---------------+------------+------------+---------+----------------+----------------+---------------+--------------+--------------+------+---------+----------------------------+----------------------------+----------------------------+----------------------------+------------------------------------+----------------------------+-------------------------------+-----------------------------------------+----------------------------------------+-------------------------------------+--------------------------------------+------------------------------------+-------------------------------------+------------------------------------+---------------------------------+----------------------------------------+---------------------------------------+------------------------------------+--------------------+-------------------------------------+-------------------------------------+----------------------------+-----------------------------+-------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Primeiro join: BOP com ER\n",
    "merged_df = pivoted_BOP.join(\n",
    "    pivoted_ER,\n",
    "    on=[\"COUNTRY\", \"TIME_PERIOD\"],\n",
    "    how=\"outer\"\n",
    ")\n",
    "\n",
    "# Segundo join: resultado anterior com IIP\n",
    "merged_df = merged_df.join(\n",
    "    pivoted_IIP,\n",
    "    on=[\"COUNTRY\", \"TIME_PERIOD\"],\n",
    "    how=\"outer\"\n",
    ")\n",
    "\n",
    "# Terceiro join: resultado anterior com IRFCL\n",
    "merged_df = merged_df.join(\n",
    "    pivoted_IRFCL,\n",
    "    on=[\"COUNTRY\", \"TIME_PERIOD\"],\n",
    "    how=\"outer\"\n",
    ")\n",
    "\n",
    "merged_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e61ec2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1266:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+----+---------+---------------+------------------+----------------+----------------+----------------+----------------+----------------+--------------+------------------+----------------------+-----------+-----------+--------------+------------+------------+---------------+------------+------------+---------------+---------------+----------------+----------------+-------------------+----------------+----------------+-------------------+-----------------+-----------------+--------------------+----------------+----------------+----------------+----------------+----------------+------------------+-----------+-----------+-----------+--------------+----------------------+---------+-----------------+-------+-----------------+----+---------+---------+---------+------------+------------+------------+------------+----------------+-------------+---------------+---------------+---------------+---------------+-------------+-------------+-------------+---------------+---------------+---------------+---------------+------------+------------+---------+----------------+----------------+---------------+--------------+--------------+------+---------+----------------------------+----------------------------+----------------------------+----------------------------+------------------------------------+----------------------------+-------------------------------+-----------------------------------------+----------------------------------------+-------------------------------------+--------------------------------------+------------------------------------+-------------------------------------+------------------------------------+---------------------------------+----------------------------------------+---------------------------------------+------------------------------------+--------------------+-------------------------------------+-------------------------------------+----------------------------+-----------------------------+-------------------------------+-----------------+----+--------------------+----------+----------+---------+\n",
      "|COUNTRY|TIME_PERIOD|UNIT|FREQUENCY|CAB/BOP/NETCD_T|CABXEF/BOP/NETCD_T|DXEF/BOP/L_NIL_T|D_F5/BOP/A_NFA_T|D_F5/BOP/L_NIL_T|D_FL/BOP/A_NFA_T|D_FL/BOP/L_NIL_T|EO/BOP/NETCD_T|FAB/BOP/NNAFANIL_T|FABXRRI/BOP/NNAFANIL_T|GS/BOP/CD_T|GS/BOP/DB_T|GS/BOP/NETCD_T|IN1/BOP/CD_T|IN1/BOP/DB_T|IN1/BOP/NETCD_T|IN2/BOP/CD_T|IN2/BOP/DB_T|IN2/BOP/NETCD_T|KAB/BOP/NETCD_T|O_F2/BOP/A_NFA_T|O_F2/BOP/L_NIL_T|O_F2/BOP/NNAFANIL_T|O_F4/BOP/A_NFA_T|O_F4/BOP/L_NIL_T|O_F4/BOP/NNAFANIL_T|O_F81/BOP/A_NFA_T|O_F81/BOP/L_NIL_T|O_F81/BOP/NNAFANIL_T|PXEF/BOP/L_NIL_T|P_F3/BOP/A_NFA_T|P_F3/BOP/L_NIL_T|P_F5/BOP/A_NFA_T|P_F5/BOP/L_NIL_T|RUE/BOP/NNAFANIL_T|R_F/BOP/A_T|SF/BOP/CD_T|SF/BOP/DB_T|SF/BOP/NETCD_T|TYPE_OF_TRANSFORMATION|FREQUENCY|          XDC_EUR|XDC_USD|          XDC_XDR|UNIT|FREQUENCY|D/IIP/A_P|D/IIP/L_P|D_F5/IIP/A_P|D_F5/IIP/L_P|D_FL/IIP/A_P|D_FL/IIP/L_P|NIIP/IIP/NETAL_P|O_F12/IIP/L_P|O_F2_NV/IIP/A_P|O_F2_NV/IIP/L_P|O_F4_NV/IIP/A_P|O_F4_NV/IIP/L_P|O_F81/IIP/A_P|O_F81/IIP/L_P|O_FL1/IIP/A_P|P_F3_MV/IIP/A_P|P_F3_MV/IIP/L_P|P_F5_MV/IIP/A_P|P_F5_MV/IIP/L_P|P_MV/IIP/A_P|P_MV/IIP/L_P|R/IIP/A_P|R_F11_MV/IIP/A_P|R_F12_MV/IIP/A_P|R_FK_MV/IIP/A_P|TA_AFR/IIP/A_P|TL_AFR/IIP/L_P|SECTOR|FREQUENCY|IRFCLDT1_IRFCL32_USD_IRFCL13|IRFCLDT1_IRFCL54_USD_IRFCL13|IRFCLDT1_IRFCL56_USD_IRFCL13|IRFCLDT1_IRFCL57_USD_IRFCL13|IRFCLDT1_IRFCL65_DIC_XDR_USD_IRFCL13|IRFCLDT1_IRFCL65_USD_IRFCL13|IRFCLDT1_IRFCLCDCFC_USD_IRFCL13|IRFCLDT2_IRFCL151_SM1MUT3M_FO_USD_IRFCL13|IRFCLDT2_IRFCL151_SM3MUTY_FO_USD_IRFCL13|IRFCLDT2_IRFCL151_SUTM_FO_USD_IRFCL13|IRFCLDT2_IRFCL1_SUTM_IN_LP_USD_IRFCL13|IRFCLDT2_IRFCL1_SUTM_SHP_USD_IRFCL13|IRFCLDT2_IRFCL24_SM1MUT3M_USD_IRFCL13|IRFCLDT2_IRFCL24_SM3MUTY_USD_IRFCL13|IRFCLDT2_IRFCL24_SUTM_USD_IRFCL13|IRFCLDT2_IRFCL26_SM1MUT3M_FO_USD_IRFCL13|IRFCLDT2_IRFCL26_SM3MUTY_FO_USD_IRFCL13|IRFCLDT2_IRFCL26_SUTM_FO_USD_IRFCL13|IRFCLDT2_USD_IRFCL13|IRFCLDT4_IRFCL11_DIC_XDRB_USD_IRFCL13|IRFCLDT4_IRFCL11_DIC_XXDR_USD_IRFCL13|IRFCLDT4_IRFCL68_USD_IRFCL13|IRFCLDT4_IRFCL69X_USD_IRFCL13|IRFCLDT4_IRFCLU97_A_USD_IRFCL13|TERRITORIAL_LEVEL|FREQ|FERT_RATIO/DM/BR_L_W|LFEXP/DM/Y|MORT/DM/DT|POP/DM/PS|\n",
      "+-------+-----------+----+---------+---------------+------------------+----------------+----------------+----------------+----------------+----------------+--------------+------------------+----------------------+-----------+-----------+--------------+------------+------------+---------------+------------+------------+---------------+---------------+----------------+----------------+-------------------+----------------+----------------+-------------------+-----------------+-----------------+--------------------+----------------+----------------+----------------+----------------+----------------+------------------+-----------+-----------+-----------+--------------+----------------------+---------+-----------------+-------+-----------------+----+---------+---------+---------+------------+------------+------------+------------+----------------+-------------+---------------+---------------+---------------+---------------+-------------+-------------+-------------+---------------+---------------+---------------+---------------+------------+------------+---------+----------------+----------------+---------------+--------------+--------------+------+---------+----------------------------+----------------------------+----------------------------+----------------------------+------------------------------------+----------------------------+-------------------------------+-----------------------------------------+----------------------------------------+-------------------------------------+--------------------------------------+------------------------------------+-------------------------------------+------------------------------------+---------------------------------+----------------------------------------+---------------------------------------+------------------------------------+--------------------+-------------------------------------+-------------------------------------+----------------------------+-----------------------------+-------------------------------+-----------------+----+--------------------+----------+----------+---------+\n",
      "|    ARE|    2000-Q1|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|3.508339250000001| 3.6725|4.946394418554536|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|             NULL|NULL|                NULL|      NULL|      NULL|     NULL|\n",
      "|    ARE|    2000-Q2|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|3.509440999999998| 3.6725|4.911157856448429|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|             NULL|NULL|                NULL|      NULL|      NULL|     NULL|\n",
      "|    ARE|    2000-Q3|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|       3.21894625| 3.6725| 4.76650300266976|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|             NULL|NULL|                NULL|      NULL|      NULL|     NULL|\n",
      "|    ARE|    2000-Q4|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|       3.41726125| 3.6725|4.784929004552361|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|             NULL|NULL|                NULL|      NULL|      NULL|     NULL|\n",
      "|    ARE|    2001-Q1|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|3.243552000000001| 3.6725|4.629740520220209|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|             NULL|NULL|                NULL|      NULL|      NULL|     NULL|\n",
      "|    ARE|    2001-Q2|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|          3.11428| 3.6725|4.574642343313052|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|             NULL|NULL|                NULL|      NULL|      NULL|     NULL|\n",
      "|    ARE|    2001-Q3|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|3.353359749999999| 3.6725|4.733884169685095|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|             NULL|NULL|                NULL|      NULL|      NULL|     NULL|\n",
      "|    ARE|    2001-Q4|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|       3.23657425| 3.6725|4.615340146484423|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|             NULL|NULL|                NULL|      NULL|      NULL|     NULL|\n",
      "|    ARE|    2002-Q1|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|3.203889000000001| 3.6725|4.579285544171245|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|             NULL|NULL|                NULL|      NULL|      NULL|     NULL|\n",
      "|    ARE|    2002-Q2|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|3.663318750000001| 3.6725|4.886132165717381|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|             NULL|NULL|                NULL|      NULL|      NULL|     NULL|\n",
      "|    ARE|    2002-Q3|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|3.621085000000002| 3.6725|4.857592195049689|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|             NULL|NULL|                NULL|      NULL|      NULL|     NULL|\n",
      "|    ARE|    2002-Q4|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|       3.85135075| 3.6725|4.992848908030975|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|             NULL|NULL|                NULL|      NULL|      NULL|     NULL|\n",
      "|    ARE|    2003-Q1|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|       4.00118875| 3.6725|5.045238860634635|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|             NULL|NULL|                NULL|      NULL|      NULL|     NULL|\n",
      "|    ARE|    2003-Q2|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|       4.19656575| 3.6725|5.144652643139716|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|             NULL|NULL|                NULL|      NULL|      NULL|     NULL|\n",
      "|    ARE|    2003-Q3|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|         4.279197| 3.6725|5.250914352546891|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|             NULL|NULL|                NULL|      NULL|      NULL|     NULL|\n",
      "|    ARE|    2003-Q4|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|        4.6383675| 3.6725|5.457225604455532|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|             NULL|NULL|                NULL|      NULL|      NULL|     NULL|\n",
      "|    ARE|    2004-Q1|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|         4.489264| 3.6725|5.437180394467624|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|             NULL|NULL|                NULL|      NULL|      NULL|     NULL|\n",
      "|    ARE|    2004-Q2|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|       4.46392375| 3.6725|5.384699974341116|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|             NULL|NULL|                NULL|      NULL|      NULL|     NULL|\n",
      "|    ARE|    2004-Q3|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|       4.55720525| 3.6725|5.394880262303561|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|             NULL|NULL|                NULL|      NULL|      NULL|     NULL|\n",
      "|    ARE|    2004-Q4|NULL|     NULL|           NULL|              NULL|            NULL|            NULL|            NULL|            NULL|            NULL|          NULL|              NULL|                  NULL|       NULL|       NULL|          NULL|        NULL|        NULL|           NULL|        NULL|        NULL|           NULL|           NULL|            NULL|            NULL|               NULL|            NULL|            NULL|               NULL|             NULL|             NULL|                NULL|            NULL|            NULL|            NULL|            NULL|            NULL|              NULL|       NULL|       NULL|       NULL|          NULL|                EOP_RT|        Q|       5.00231225| 3.6725|5.703419100746684|NULL|     NULL|     NULL|     NULL|        NULL|        NULL|        NULL|        NULL|            NULL|         NULL|           NULL|           NULL|           NULL|           NULL|         NULL|         NULL|         NULL|           NULL|           NULL|           NULL|           NULL|        NULL|        NULL|     NULL|            NULL|            NULL|           NULL|          NULL|          NULL|  NULL|     NULL|                        NULL|                        NULL|                        NULL|                        NULL|                                NULL|                        NULL|                           NULL|                                     NULL|                                    NULL|                                 NULL|                                  NULL|                                NULL|                                 NULL|                                NULL|                             NULL|                                    NULL|                                   NULL|                                NULL|                NULL|                                 NULL|                                 NULL|                        NULL|                         NULL|                           NULL|             NULL|NULL|                NULL|      NULL|      NULL|     NULL|\n",
      "+-------+-----------+----+---------+---------------+------------------+----------------+----------------+----------------+----------------+----------------+--------------+------------------+----------------------+-----------+-----------+--------------+------------+------------+---------------+------------+------------+---------------+---------------+----------------+----------------+-------------------+----------------+----------------+-------------------+-----------------+-----------------+--------------------+----------------+----------------+----------------+----------------+----------------+------------------+-----------+-----------+-----------+--------------+----------------------+---------+-----------------+-------+-----------------+----+---------+---------+---------+------------+------------+------------+------------+----------------+-------------+---------------+---------------+---------------+---------------+-------------+-------------+-------------+---------------+---------------+---------------+---------------+------------+------------+---------+----------------+----------------+---------------+--------------+--------------+------+---------+----------------------------+----------------------------+----------------------------+----------------------------+------------------------------------+----------------------------+-------------------------------+-----------------------------------------+----------------------------------------+-------------------------------------+--------------------------------------+------------------------------------+-------------------------------------+------------------------------------+---------------------------------+----------------------------------------+---------------------------------------+------------------------------------+--------------------+-------------------------------------+-------------------------------------+----------------------------+-----------------------------+-------------------------------+-----------------+----+--------------------+----------+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "pivoted_DM = pivoted_DM.withColumnRenamed(\"REF_AREA\", \"COUNTRY\")\n",
    "\n",
    "# padronize o período: ano em ambos, por exemplo\n",
    "a = merged_df.withColumn(\"YEAR\", F.split(\"TIME_PERIOD\", \"-\").getItem(0).cast(\"int\"))\n",
    "b = pivoted_DM.withColumn(\"YEAR\", F.col(\"TIME_PERIOD\").cast(\"int\")).drop(\"TIME_PERIOD\")\n",
    "\n",
    "# agora use on=[\"COUNTRY\", \"YEAR\"] para o join\n",
    "final_df = a.join(b, on=[\"COUNTRY\", \"YEAR\"], how=\"left\")\n",
    "# -> só 1 coluna COUNTRY e 1 coluna YEAR no resultado\n",
    "\n",
    "merged_df = final_df.drop(\"YEAR\")\n",
    "merged_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af91515f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5603\n",
      "109\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.count())\n",
    "print(len(merged_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1d304a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('COUNTRY', 'string'),\n",
       " ('TIME_PERIOD', 'string'),\n",
       " ('UNIT', 'string'),\n",
       " ('FREQUENCY', 'string'),\n",
       " ('CAB/BOP/NETCD_T', 'double'),\n",
       " ('CABXEF/BOP/NETCD_T', 'double'),\n",
       " ('DXEF/BOP/L_NIL_T', 'double'),\n",
       " ('D_F5/BOP/A_NFA_T', 'double'),\n",
       " ('D_F5/BOP/L_NIL_T', 'double'),\n",
       " ('D_FL/BOP/A_NFA_T', 'double'),\n",
       " ('D_FL/BOP/L_NIL_T', 'double'),\n",
       " ('EO/BOP/NETCD_T', 'double'),\n",
       " ('FAB/BOP/NNAFANIL_T', 'double'),\n",
       " ('FABXRRI/BOP/NNAFANIL_T', 'double'),\n",
       " ('GS/BOP/CD_T', 'double'),\n",
       " ('GS/BOP/DB_T', 'double'),\n",
       " ('GS/BOP/NETCD_T', 'double'),\n",
       " ('IN1/BOP/CD_T', 'double'),\n",
       " ('IN1/BOP/DB_T', 'double'),\n",
       " ('IN1/BOP/NETCD_T', 'double'),\n",
       " ('IN2/BOP/CD_T', 'double'),\n",
       " ('IN2/BOP/DB_T', 'double'),\n",
       " ('IN2/BOP/NETCD_T', 'double'),\n",
       " ('KAB/BOP/NETCD_T', 'double'),\n",
       " ('O_F2/BOP/A_NFA_T', 'double'),\n",
       " ('O_F2/BOP/L_NIL_T', 'double'),\n",
       " ('O_F2/BOP/NNAFANIL_T', 'double'),\n",
       " ('O_F4/BOP/A_NFA_T', 'double'),\n",
       " ('O_F4/BOP/L_NIL_T', 'double'),\n",
       " ('O_F4/BOP/NNAFANIL_T', 'double'),\n",
       " ('O_F81/BOP/A_NFA_T', 'double'),\n",
       " ('O_F81/BOP/L_NIL_T', 'double'),\n",
       " ('O_F81/BOP/NNAFANIL_T', 'double'),\n",
       " ('PXEF/BOP/L_NIL_T', 'double'),\n",
       " ('P_F3/BOP/A_NFA_T', 'double'),\n",
       " ('P_F3/BOP/L_NIL_T', 'double'),\n",
       " ('P_F5/BOP/A_NFA_T', 'double'),\n",
       " ('P_F5/BOP/L_NIL_T', 'double'),\n",
       " ('RUE/BOP/NNAFANIL_T', 'double'),\n",
       " ('R_F/BOP/A_T', 'double'),\n",
       " ('SF/BOP/CD_T', 'double'),\n",
       " ('SF/BOP/DB_T', 'double'),\n",
       " ('SF/BOP/NETCD_T', 'double'),\n",
       " ('TYPE_OF_TRANSFORMATION', 'string'),\n",
       " ('FREQUENCY', 'string'),\n",
       " ('XDC_EUR', 'double'),\n",
       " ('XDC_USD', 'double'),\n",
       " ('XDC_XDR', 'double'),\n",
       " ('UNIT', 'string'),\n",
       " ('FREQUENCY', 'string'),\n",
       " ('D/IIP/A_P', 'double'),\n",
       " ('D/IIP/L_P', 'double'),\n",
       " ('D_F5/IIP/A_P', 'double'),\n",
       " ('D_F5/IIP/L_P', 'double'),\n",
       " ('D_FL/IIP/A_P', 'double'),\n",
       " ('D_FL/IIP/L_P', 'double'),\n",
       " ('NIIP/IIP/NETAL_P', 'double'),\n",
       " ('O_F12/IIP/L_P', 'double'),\n",
       " ('O_F2_NV/IIP/A_P', 'double'),\n",
       " ('O_F2_NV/IIP/L_P', 'double'),\n",
       " ('O_F4_NV/IIP/A_P', 'double'),\n",
       " ('O_F4_NV/IIP/L_P', 'double'),\n",
       " ('O_F81/IIP/A_P', 'double'),\n",
       " ('O_F81/IIP/L_P', 'double'),\n",
       " ('O_FL1/IIP/A_P', 'double'),\n",
       " ('P_F3_MV/IIP/A_P', 'double'),\n",
       " ('P_F3_MV/IIP/L_P', 'double'),\n",
       " ('P_F5_MV/IIP/A_P', 'double'),\n",
       " ('P_F5_MV/IIP/L_P', 'double'),\n",
       " ('P_MV/IIP/A_P', 'double'),\n",
       " ('P_MV/IIP/L_P', 'double'),\n",
       " ('R/IIP/A_P', 'double'),\n",
       " ('R_F11_MV/IIP/A_P', 'double'),\n",
       " ('R_F12_MV/IIP/A_P', 'double'),\n",
       " ('R_FK_MV/IIP/A_P', 'double'),\n",
       " ('TA_AFR/IIP/A_P', 'double'),\n",
       " ('TL_AFR/IIP/L_P', 'double'),\n",
       " ('SECTOR', 'string'),\n",
       " ('FREQUENCY', 'string'),\n",
       " ('IRFCLDT1_IRFCL32_USD_IRFCL13', 'double'),\n",
       " ('IRFCLDT1_IRFCL54_USD_IRFCL13', 'double'),\n",
       " ('IRFCLDT1_IRFCL56_USD_IRFCL13', 'double'),\n",
       " ('IRFCLDT1_IRFCL57_USD_IRFCL13', 'double'),\n",
       " ('IRFCLDT1_IRFCL65_DIC_XDR_USD_IRFCL13', 'double'),\n",
       " ('IRFCLDT1_IRFCL65_USD_IRFCL13', 'double'),\n",
       " ('IRFCLDT1_IRFCLCDCFC_USD_IRFCL13', 'double'),\n",
       " ('IRFCLDT2_IRFCL151_SM1MUT3M_FO_USD_IRFCL13', 'double'),\n",
       " ('IRFCLDT2_IRFCL151_SM3MUTY_FO_USD_IRFCL13', 'double'),\n",
       " ('IRFCLDT2_IRFCL151_SUTM_FO_USD_IRFCL13', 'double'),\n",
       " ('IRFCLDT2_IRFCL1_SUTM_IN_LP_USD_IRFCL13', 'double'),\n",
       " ('IRFCLDT2_IRFCL1_SUTM_SHP_USD_IRFCL13', 'double'),\n",
       " ('IRFCLDT2_IRFCL24_SM1MUT3M_USD_IRFCL13', 'double'),\n",
       " ('IRFCLDT2_IRFCL24_SM3MUTY_USD_IRFCL13', 'double'),\n",
       " ('IRFCLDT2_IRFCL24_SUTM_USD_IRFCL13', 'double'),\n",
       " ('IRFCLDT2_IRFCL26_SM1MUT3M_FO_USD_IRFCL13', 'double'),\n",
       " ('IRFCLDT2_IRFCL26_SM3MUTY_FO_USD_IRFCL13', 'double'),\n",
       " ('IRFCLDT2_IRFCL26_SUTM_FO_USD_IRFCL13', 'double'),\n",
       " ('IRFCLDT2_USD_IRFCL13', 'double'),\n",
       " ('IRFCLDT4_IRFCL11_DIC_XDRB_USD_IRFCL13', 'double'),\n",
       " ('IRFCLDT4_IRFCL11_DIC_XXDR_USD_IRFCL13', 'double'),\n",
       " ('IRFCLDT4_IRFCL68_USD_IRFCL13', 'double'),\n",
       " ('IRFCLDT4_IRFCL69X_USD_IRFCL13', 'double'),\n",
       " ('IRFCLDT4_IRFCLU97_A_USD_IRFCL13', 'double'),\n",
       " ('TERRITORIAL_LEVEL', 'string'),\n",
       " ('FREQ', 'string'),\n",
       " ('FERT_RATIO/DM/BR_L_W', 'double'),\n",
       " ('LFEXP/DM/Y', 'double'),\n",
       " ('MORT/DM/DT', 'double'),\n",
       " ('POP/DM/PS', 'double')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ac6582fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Foram detectadas 97 colunas numéricas.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import NumericType\n",
    "\n",
    "# Colunas-chave (ajuste se necessário)\n",
    "KEY_COLS = [\"COUNTRY\", \"TIME_PERIOD\"]\n",
    "\n",
    "# 1) Detectar todas as colunas numéricas (excluindo chaves e datas)\n",
    "num_cols = [\n",
    "    f.name for f in merged_df.schema.fields\n",
    "    if isinstance(f.dataType, NumericType) and f.name not in KEY_COLS\n",
    "]\n",
    "print(f\"[INFO] Foram detectadas {len(num_cols)} colunas numéricas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "274d2732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _box_stats_for_metric(sdf, colname, rel_tol=1e-6):\n",
    "    \"\"\"\n",
    "    Calcula estatísticas de boxplot (Tukey) no Spark e retorna\n",
    "    um dict compatível com matplotlib.pyplot.bxp.\n",
    "    \"\"\"\n",
    "    # Quantis aproximados (rápidos e escaláveis)\n",
    "    q = sdf.approxQuantile(colname, [0.25, 0.5, 0.75], rel_tol)\n",
    "    # Se a coluna for toda nula/vazia, devolve box vazio seguro\n",
    "    if q is None or len(q) != 3:\n",
    "        return dict(med=None, q1=None, q3=None, whislo=None, whishi=None, fliers=[])\n",
    "\n",
    "    q1, med, q3 = q\n",
    "    if q1 is None or q3 is None:\n",
    "        return dict(med=None, q1=None, q3=None, whislo=None, whishi=None, fliers=[])\n",
    "\n",
    "    iqr = q3 - q1\n",
    "    low = q1 - 1.5 * iqr\n",
    "    high = q3 + 1.5 * iqr\n",
    "\n",
    "    # Limitar whiskers ao min/max dos pontos dentro do intervalo [low, high]\n",
    "    inside = sdf.select(F.col(colname).alias(\"v\")).where(\n",
    "        F.col(\"v\").isNotNull() & (F.col(\"v\") >= low) & (F.col(\"v\") <= high)\n",
    "    )\n",
    "\n",
    "    # Se não houver pontos \"inside\", caia para min/max gerais (evita erro)\n",
    "    if inside.rdd.isEmpty():\n",
    "        bounds = sdf.select(F.min(colname).alias(\"lo\"), F.max(colname).alias(\"hi\")).collect()[0]\n",
    "        lo = bounds.lo\n",
    "        hi = bounds.hi\n",
    "    else:\n",
    "        bounds = inside.select(F.min(\"v\").alias(\"lo\"), F.max(\"v\").alias(\"hi\")).collect()[0]\n",
    "        lo = bounds.lo\n",
    "        hi = bounds.hi\n",
    "\n",
    "    return dict(med=med, q1=q1, q3=q3, whislo=lo, whishi=hi, fliers=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "41951dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _box_stats_for_metric(sdf, colname, rel_tol=1e-6, max_fliers=500):\n",
    "    \"\"\"\n",
    "    Calcula estatísticas de boxplot (Tukey) no Spark e retorna\n",
    "    um dict compatível com Axes.bxp, agora com 'fliers' preenchido.\n",
    "    \"\"\"\n",
    "    q = sdf.approxQuantile(colname, [0.25, 0.5, 0.75], rel_tol)\n",
    "    if not q or len(q) != 3:\n",
    "        return dict(med=None, q1=None, q3=None, whislo=None, whishi=None, fliers=[])\n",
    "\n",
    "    q1, med, q3 = q\n",
    "    if q1 is None or q3 is None:\n",
    "        return dict(med=None, q1=None, q3=None, whislo=None, whishi=None, fliers=[])\n",
    "\n",
    "    iqr = q3 - q1\n",
    "    low = q1 - 1.5 * iqr\n",
    "    high = q3 + 1.5 * iqr\n",
    "\n",
    "    inside = sdf.select(F.col(colname).alias(\"v\")).where(\n",
    "        F.col(\"v\").isNotNull() & (F.col(\"v\") >= low) & (F.col(\"v\") <= high)\n",
    "    )\n",
    "\n",
    "    if inside.rdd.isEmpty():\n",
    "        bounds = sdf.select(F.min(colname).alias(\"lo\"), F.max(colname).alias(\"hi\")).collect()[0]\n",
    "        lo = bounds.lo\n",
    "        hi = bounds.hi\n",
    "    else:\n",
    "        bounds = inside.select(F.min(\"v\").alias(\"lo\"), F.max(\"v\").alias(\"hi\")).collect()[0]\n",
    "        lo = bounds.lo\n",
    "        hi = bounds.hi\n",
    "\n",
    "    # ---- calcular outliers (fliers) ----\n",
    "    fliers_df = sdf.select(F.col(colname).alias(\"v\")).where(\n",
    "        F.col(\"v\").isNotNull() & ((F.col(\"v\") < low) | (F.col(\"v\") > high))\n",
    "    )\n",
    "    # limite de segurança para não trazer milhões de pontos\n",
    "    fliers_vals = (\n",
    "        fliers_df\n",
    "        .limit(max_fliers)              # cap opcional\n",
    "        .rdd.map(lambda r: float(r[0])) # lista de floats\n",
    "        .collect()\n",
    "    )\n",
    "\n",
    "    return dict(med=med, q1=q1, q3=q3, whislo=lo, whishi=hi, fliers=fliers_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9e77158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def _sample_values(sdf, colname, max_points=1000, frac=None):\n",
    "    q = sdf.select(F.col(colname).alias(\"v\")).where(F.col(\"v\").isNotNull())\n",
    "    if frac is not None:\n",
    "        q = q.sample(withReplacement=False, fraction=frac, seed=42)\n",
    "    return q.limit(max_points).rdd.map(lambda r: float(r[0])).collect()\n",
    "\n",
    "\n",
    "\n",
    "def plot_boxplots_by_country(sdf, country, metrics=None, max_metrics=5, rel_tol=1e-6, title_suffix=\"ANTES\"):\n",
    "    \"\"\"\n",
    "    Plota boxplots para TODAS (ou um subconjunto) das colunas numéricas de um país.\n",
    "    - sdf: DataFrame Spark (ex.: merged_df)\n",
    "    - country: string (ex.: \"BRA\")\n",
    "    - metrics: lista de colunas numéricas (default: todas detectadas)\n",
    "    - max_metrics: limite para não poluir o gráfico\n",
    "    - rel_tol: tolerância do approxQuantile\n",
    "    - title_suffix: texto no título (\"ANTES\", \"DEPOIS\", etc.)\n",
    "    \"\"\"\n",
    "    if metrics is None:\n",
    "        metrics = num_cols\n",
    "    metrics = metrics[:max_metrics]\n",
    "\n",
    "    # Recorte por país e remover linhas totalmente nulas nas colunas analisadas\n",
    "    base = sdf.filter(F.col(\"COUNTRY\") == country)\n",
    "    # (opcional) se quiser garantir que haja valores: base = base.na.drop(subset=metrics)\n",
    "\n",
    "    # Calcula as stats no Spark e traz só os números\n",
    "    stats = [_box_stats_for_metric(base, m, rel_tol=rel_tol) for m in metrics]\n",
    "\n",
    "    # Caso alguma métrica não tenha dados, substitui por um box \"vazio\" (evita erro do bxp)\n",
    "    cleaned_stats = []\n",
    "    cleaned_labels = []\n",
    "    for m, s in zip(metrics, stats):\n",
    "        if None in (s[\"q1\"], s[\"q3\"], s[\"med\"], s[\"whislo\"], s[\"whishi\"]):\n",
    "            # pula métricas sem dados válidos\n",
    "            continue\n",
    "        cleaned_stats.append(s)\n",
    "        cleaned_labels.append(m)\n",
    "\n",
    "    if not cleaned_stats:\n",
    "        print(f\"[WARN] Sem dados numéricos válidos para {country} nas métricas selecionadas.\")\n",
    "        return\n",
    "\n",
    "\n",
    "    fig_w = max(8, len(cleaned_stats)*0.9)\n",
    "    fig, ax = plt.subplots(figsize=(fig_w, 6))\n",
    "\n",
    "    # usar o método do eixo em vez de plt.bxp\n",
    "    ax.bxp(cleaned_stats, showfliers=True)\n",
    "\n",
    "    # Depois do ax.bxp(...):\n",
    "    for i, m in enumerate(cleaned_labels, start=1):\n",
    "        vals = _sample_values(base, m, max_points=800)  # coleta amostra\n",
    "        if not vals: \n",
    "            continue\n",
    "        x = np.random.normal(loc=i, scale=0.04, size=len(vals))  # jitter ao redor da x=i\n",
    "        ax.scatter(x, vals, alpha=0.35, s=10)  # pontos de todos os valores (amostrados)\n",
    "\n",
    "    ax.set_xticks(range(1, len(cleaned_labels) + 1))\n",
    "    ax.set_xticklabels(cleaned_labels, rotation=45, ha=\"right\")\n",
    "    ax.set_title(f\"Boxplots ({title_suffix}) — {country}\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fafc588c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/17 12:36:01 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:36:03 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:36:07 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:36:12 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:36:14 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:36:18 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:36:20 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:36:21 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:36:25 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:36:27 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:36:30 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:36:33 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:36:36 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:36:38 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:36:42 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:36:44 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:36:46 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:36:47 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:36:49 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:36:50 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plot_boxplots_by_country(merged_df, country=\"BRA\", title_suffix=\"ANTES\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0c7b2e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "def build_iqr_thresholds(sdf, group_cols=[\"COUNTRY\"], metrics=None, accuracy=200, whisker=1.5):\n",
    "    \"\"\"\n",
    "    Calcula Q1/Q3/IQR/low/high por grupo (ex.: por COUNTRY) para várias métricas,\n",
    "    usando percentile_approx (agregador nativo do Spark).\n",
    "    Retorna um DF com colunas: group_cols + para cada métrica: __q1, __q3, __iqr, __low, __high.\n",
    "    \"\"\"\n",
    "    if metrics is None:\n",
    "        # use sua lista já detectada de numéricas\n",
    "        metrics = [f.name for f in sdf.schema.fields if isinstance(f.dataType, NumericType) and f.name not in [\"COUNTRY\",\"TIME_PERIOD\"]]\n",
    "\n",
    "    # agrega Q1 e Q3 por grupo\n",
    "    agg_exprs = []\n",
    "    for c in metrics:\n",
    "        agg_exprs += [\n",
    "            F.expr(f\"percentile_approx({c}, 0.25, {accuracy})\").alias(f\"{c}__q1\"),\n",
    "            F.expr(f\"percentile_approx({c}, 0.75, {accuracy})\").alias(f\"{c}__q3\"),\n",
    "        ]\n",
    "\n",
    "    th = sdf.groupBy(*group_cols).agg(*agg_exprs)\n",
    "\n",
    "    # calcula IQR e limites, com guardas para casos degenerados (iqr nulo/zero)\n",
    "    for c in metrics:\n",
    "        q1 = F.col(f\"{c}__q1\")\n",
    "        q3 = F.col(f\"{c}__q3\")\n",
    "        iqr = (q3 - q1)\n",
    "        th = th.withColumn(f\"{c}__iqr\", iqr) \\\n",
    "               .withColumn(\n",
    "                   f\"{c}__low\",\n",
    "                   F.when(q1.isNull() | q3.isNull() | (iqr <= 0), F.lit(None)).otherwise(q1 - whisker * iqr)\n",
    "               ).withColumn(\n",
    "                   f\"{c}__high\",\n",
    "                   F.when(q1.isNull() | q3.isNull() | (iqr <= 0), F.lit(None)).otherwise(q3 + whisker * iqr)\n",
    "               )\n",
    "    return th\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c64a0e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import NumericType\n",
    "\n",
    "def build_iqr_thresholds(sdf, group_cols=[\"COUNTRY\"], metrics=None, accuracy=200, whisker=1.5):\n",
    "    \"\"\"\n",
    "    Calcula Q1/Q3/IQR/low/high por grupo para várias métricas\n",
    "    usando percentile_approx em API de coluna (seguro p/ nomes com caracteres especiais).\n",
    "    \"\"\"\n",
    "    if metrics is None:\n",
    "        metrics = [\n",
    "            f.name for f in sdf.schema.fields\n",
    "            if isinstance(f.dataType, NumericType) and f.name not in [\"COUNTRY\",\"TIME_PERIOD\"]\n",
    "        ]\n",
    "\n",
    "    # agrega Q1 e Q3 por grupo usando a API de coluna\n",
    "    agg_exprs = []\n",
    "    for c in metrics:\n",
    "        agg_exprs += [\n",
    "            F.percentile_approx(F.col(c), 0.25, accuracy).alias(f\"{c}__q1\"),\n",
    "            F.percentile_approx(F.col(c), 0.75, accuracy).alias(f\"{c}__q3\"),\n",
    "        ]\n",
    "\n",
    "    th = sdf.groupBy(*group_cols).agg(*agg_exprs)\n",
    "\n",
    "    # calcula IQR e limites com guardas\n",
    "    for c in metrics:\n",
    "        q1 = F.col(f\"{c}__q1\")\n",
    "        q3 = F.col(f\"{c}__q3\")\n",
    "        iqr = (q3 - q1)\n",
    "        th = (\n",
    "            th.withColumn(f\"{c}__iqr\", iqr)\n",
    "              .withColumn(\n",
    "                  f\"{c}__low\",\n",
    "                  F.when(q1.isNull() | q3.isNull() | (iqr <= 0), F.lit(None)).otherwise(q1 - whisker * iqr)\n",
    "              )\n",
    "              .withColumn(\n",
    "                  f\"{c}__high\",\n",
    "                  F.when(q1.isNull() | q3.isNull() | (iqr <= 0), F.lit(None)).otherwise(q3 + whisker * iqr)\n",
    "              )\n",
    "        )\n",
    "    return th\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e02c05ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import NumericType\n",
    "\n",
    "def nullify_outliers_all(sdf, group_cols=[\"COUNTRY\"], metrics=None, whisker=1.5, accuracy=200):\n",
    "    \"\"\"\n",
    "    Substitui por NULL os outliers (v < low ou v > high) em TODAS as métricas,\n",
    "    por grupo (ex.: por COUNTRY). Mantém valores dentro do intervalo e nulos originais.\n",
    "    \"\"\"\n",
    "    if metrics is None:\n",
    "        metrics = [f.name for f in sdf.schema.fields if isinstance(f.dataType, NumericType) and f.name not in [\"COUNTRY\",\"TIME_PERIOD\"]]\n",
    "\n",
    "    # calcula limiares e faz join\n",
    "    th = build_iqr_thresholds(sdf, group_cols, metrics, accuracy=accuracy, whisker=whisker)\n",
    "    df = sdf.join(th, on=group_cols, how=\"left\")\n",
    "\n",
    "    # aplica nulificação por métrica\n",
    "    out = df\n",
    "    schema_map = {f.name: f.dataType for f in sdf.schema.fields}  # para cast de NULL seguro\n",
    "    for c in metrics:\n",
    "        lo = F.col(f\"{c}__low\")\n",
    "        hi = F.col(f\"{c}__high\")\n",
    "        # se low/high indisponíveis (IQR==0 ou quantis nulos), não mexe na coluna\n",
    "        out = out.withColumn(\n",
    "            c,\n",
    "            F.when(lo.isNull() | hi.isNull(), F.col(c)) \\\n",
    "             .when(F.col(c).isNull(), F.col(c)) \\\n",
    "             .when((F.col(c) < lo) | (F.col(c) > hi), F.lit(None).cast(schema_map[c])) \\\n",
    "             .otherwise(F.col(c))\n",
    "        )\n",
    "\n",
    "    # remove colunas auxiliares\n",
    "    aux_cols = [col for col in out.columns if col.endswith((\"__q1\",\"__q3\",\"__iqr\",\"__low\",\"__high\"))]\n",
    "    return out.drop(*aux_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9a3cdcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DXEF/BOP/L_NIL_T: nulos antes=801, depois=1060, inseridos=259\n"
     ]
    }
   ],
   "source": [
    "# nulificar outliers por país (todas as métricas numéricas)\n",
    "clean_df = nullify_outliers_all(merged_df, group_cols=[\"COUNTRY\"], whisker=1.5, accuracy=200)\n",
    "\n",
    "# opcional: verificar quantos valores viraram NULL em uma métrica\n",
    "m = \"DXEF/BOP/L_NIL_T\"  # exemplo\n",
    "before_nulls = merged_df.where(F.col(m).isNull()).count()\n",
    "after_nulls  = clean_df.where(F.col(m).isNull()).count()\n",
    "print(f\"{m}: nulos antes={before_nulls}, depois={after_nulls}, inseridos={after_nulls - before_nulls}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e449eec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-----+\n",
      "|COUNTRY|TIME_PERIOD|count|\n",
      "+-------+-----------+-----+\n",
      "|    AUS|    2023-Q4|    1|\n",
      "|    BEL|    2009-Q2|    1|\n",
      "|    BRA|    2005-Q1|    1|\n",
      "|    BRA|    2023-Q2|    1|\n",
      "|    CHE|    2015-Q2|    1|\n",
      "|    CHN|    2012-Q2|    1|\n",
      "|    COL|    2004-Q3|    1|\n",
      "|    EGY|    2022-Q1|    1|\n",
      "|    EGY|    2023-Q4|    1|\n",
      "|    FRA|    2008-Q3|    1|\n",
      "|    GBR|    2012-Q2|    1|\n",
      "|    GBR|    2022-Q1|    1|\n",
      "|    GHA|    2008-Q2|    1|\n",
      "|    GHA|    2011-Q1|    1|\n",
      "|    GHA|    2025-Q2|    1|\n",
      "|    HKG|    2012-Q2|    1|\n",
      "|    IDN|    2001-Q3|    1|\n",
      "|    JPN|    2019-Q2|    1|\n",
      "|    KEN|    2014-Q2|    1|\n",
      "|    KEN|    2023-Q3|    1|\n",
      "+-------+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exemplo: contar registros por país\n",
    "count = clean_df.groupBy([\"COUNTRY\", \"TIME_PERIOD\"]).count()\n",
    "# Para ordenar por contagem decrescente:\n",
    "count_sorted = count.orderBy(\"count\", ascending=False)\n",
    "count_sorted.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "94c14ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Só há uma linha distinta.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/17 12:40:35 WARN DAGScheduler: Broadcasting large task binary with size 1200.4 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+----+---------+-------------------+-------------------+-----------------+-----------------+-------------------+-----------------+--------------------+-----------------+------------------+----------------------+--------------------+--------------------+-----------------+---------------+-------------------+---------------+-----------------+-------------------+-----------------+-----------------+-----------------+-----------------+--------------------+----------------+-----------------+-------------------+-------------------+-----------------+--------------------+----------------+-----------------+-----------------+-----------------+-----------------+-------------------+-------------+--------------+----------------+-----------------+----------------------+---------+-------+-------+-------+----+---------+--------------+--------------+-------------+--------------+--------------+--------------+----------------+-------------+---------------+---------------+---------------+---------------+-------------+-------------+--------------+---------------+---------------+---------------+---------------+--------------+---------------+-------------+----------------+----------------+---------------+--------------------+-------------------+--------+---------+----------------------------+----------------------------+----------------------------+----------------------------+------------------------------------+----------------------------+-------------------------------+-----------------------------------------+----------------------------------------+-------------------------------------+--------------------------------------+------------------------------------+-------------------------------------+------------------------------------+---------------------------------+----------------------------------------+---------------------------------------+------------------------------------+--------------------+-------------------------------------+-------------------------------------+----------------------------+-----------------------------+-------------------------------+-----------------+----+--------------------+----------+----------+-----------+\n",
      "|COUNTRY|TIME_PERIOD|UNIT|FREQUENCY|    CAB/BOP/NETCD_T| CABXEF/BOP/NETCD_T| DXEF/BOP/L_NIL_T| D_F5/BOP/A_NFA_T|   D_F5/BOP/L_NIL_T| D_FL/BOP/A_NFA_T|    D_FL/BOP/L_NIL_T|   EO/BOP/NETCD_T|FAB/BOP/NNAFANIL_T|FABXRRI/BOP/NNAFANIL_T|         GS/BOP/CD_T|         GS/BOP/DB_T|   GS/BOP/NETCD_T|   IN1/BOP/CD_T|       IN1/BOP/DB_T|IN1/BOP/NETCD_T|     IN2/BOP/CD_T|       IN2/BOP/DB_T|  IN2/BOP/NETCD_T|  KAB/BOP/NETCD_T| O_F2/BOP/A_NFA_T| O_F2/BOP/L_NIL_T| O_F2/BOP/NNAFANIL_T|O_F4/BOP/A_NFA_T| O_F4/BOP/L_NIL_T|O_F4/BOP/NNAFANIL_T|  O_F81/BOP/A_NFA_T|O_F81/BOP/L_NIL_T|O_F81/BOP/NNAFANIL_T|PXEF/BOP/L_NIL_T| P_F3/BOP/A_NFA_T| P_F3/BOP/L_NIL_T| P_F5/BOP/A_NFA_T| P_F5/BOP/L_NIL_T| RUE/BOP/NNAFANIL_T|  R_F/BOP/A_T|   SF/BOP/CD_T|     SF/BOP/DB_T|   SF/BOP/NETCD_T|TYPE_OF_TRANSFORMATION|FREQUENCY|XDC_EUR|XDC_USD|XDC_XDR|UNIT|FREQUENCY|     D/IIP/A_P|     D/IIP/L_P| D_F5/IIP/A_P|  D_F5/IIP/L_P|  D_FL/IIP/A_P|  D_FL/IIP/L_P|NIIP/IIP/NETAL_P|O_F12/IIP/L_P|O_F2_NV/IIP/A_P|O_F2_NV/IIP/L_P|O_F4_NV/IIP/A_P|O_F4_NV/IIP/L_P|O_F81/IIP/A_P|O_F81/IIP/L_P| O_FL1/IIP/A_P|P_F3_MV/IIP/A_P|P_F3_MV/IIP/L_P|P_F5_MV/IIP/A_P|P_F5_MV/IIP/L_P|  P_MV/IIP/A_P|   P_MV/IIP/L_P|    R/IIP/A_P|R_F11_MV/IIP/A_P|R_F12_MV/IIP/A_P|R_FK_MV/IIP/A_P|      TA_AFR/IIP/A_P|     TL_AFR/IIP/L_P|  SECTOR|FREQUENCY|IRFCLDT1_IRFCL32_USD_IRFCL13|IRFCLDT1_IRFCL54_USD_IRFCL13|IRFCLDT1_IRFCL56_USD_IRFCL13|IRFCLDT1_IRFCL57_USD_IRFCL13|IRFCLDT1_IRFCL65_DIC_XDR_USD_IRFCL13|IRFCLDT1_IRFCL65_USD_IRFCL13|IRFCLDT1_IRFCLCDCFC_USD_IRFCL13|IRFCLDT2_IRFCL151_SM1MUT3M_FO_USD_IRFCL13|IRFCLDT2_IRFCL151_SM3MUTY_FO_USD_IRFCL13|IRFCLDT2_IRFCL151_SUTM_FO_USD_IRFCL13|IRFCLDT2_IRFCL1_SUTM_IN_LP_USD_IRFCL13|IRFCLDT2_IRFCL1_SUTM_SHP_USD_IRFCL13|IRFCLDT2_IRFCL24_SM1MUT3M_USD_IRFCL13|IRFCLDT2_IRFCL24_SM3MUTY_USD_IRFCL13|IRFCLDT2_IRFCL24_SUTM_USD_IRFCL13|IRFCLDT2_IRFCL26_SM1MUT3M_FO_USD_IRFCL13|IRFCLDT2_IRFCL26_SM3MUTY_FO_USD_IRFCL13|IRFCLDT2_IRFCL26_SUTM_FO_USD_IRFCL13|IRFCLDT2_USD_IRFCL13|IRFCLDT4_IRFCL11_DIC_XDRB_USD_IRFCL13|IRFCLDT4_IRFCL11_DIC_XXDR_USD_IRFCL13|IRFCLDT4_IRFCL68_USD_IRFCL13|IRFCLDT4_IRFCL69X_USD_IRFCL13|IRFCLDT4_IRFCLU97_A_USD_IRFCL13|TERRITORIAL_LEVEL|FREQ|FERT_RATIO/DM/BR_L_W|LFEXP/DM/Y|MORT/DM/DT|  POP/DM/PS|\n",
      "+-------+-----------+----+---------+-------------------+-------------------+-----------------+-----------------+-------------------+-----------------+--------------------+-----------------+------------------+----------------------+--------------------+--------------------+-----------------+---------------+-------------------+---------------+-----------------+-------------------+-----------------+-----------------+-----------------+-----------------+--------------------+----------------+-----------------+-------------------+-------------------+-----------------+--------------------+----------------+-----------------+-----------------+-----------------+-----------------+-------------------+-------------+--------------+----------------+-----------------+----------------------+---------+-------+-------+-------+----+---------+--------------+--------------+-------------+--------------+--------------+--------------+----------------+-------------+---------------+---------------+---------------+---------------+-------------+-------------+--------------+---------------+---------------+---------------+---------------+--------------+---------------+-------------+----------------+----------------+---------------+--------------------+-------------------+--------+---------+----------------------------+----------------------------+----------------------------+----------------------------+------------------------------------+----------------------------+-------------------------------+-----------------------------------------+----------------------------------------+-------------------------------------+--------------------------------------+------------------------------------+-------------------------------------+------------------------------------+---------------------------------+----------------------------------------+---------------------------------------+------------------------------------+--------------------+-------------------------------------+-------------------------------------+----------------------------+-----------------------------+-------------------------------+-----------------+----+--------------------+----------+----------+-----------+\n",
      "|    ESP|    2016-Q4| USD|        Q|9.705113085937502E9|9.707270976562498E9|1.5698654296875E9|2.2258641796875E9|1.07711110546875E10|2.6488107421875E9|-9.201245625000002E9|2.4092848828125E9| 1.324513265625E10|  1.299589628906251E10|1.032324085546875E11|9.480368777343752E10|8.4297997265625E9|1.7970913125E10|1.41676308984375E10|3.80220328125E9|4.6880173828125E9|7.213828359375001E9|-2.526889921875E9|1.1318136328125E9|-4.654570078125E9|1.6302863671875E9|-6.283777500000001E9|5.828462578125E9|-3.657624609375E9|9.486087187500002E9|9.386824218750001E7| 1.422049921875E9|  -1.3281816796875E9|  4.3416759375E9|5.8921203515625E9|2.3855480859375E9|5.1088060546875E9|1.9561278515625E9|2.521125799859338E8|2.503153125E8|2.8052578125E8|4.671833203125E8|-1.866575390625E8|                  NULL|     NULL|   NULL|   NULL|   NULL| USD|        Q|7.239611505E11|7.738084854E11|5.81525888E11|5.208951101E11|1.424352625E11|2.529123212E11| -9.978268715E11|  3.7989764E9| 2.649501432E11| 6.845947319E11| 1.127971328E11| 2.053903309E11|2.25925253E10|2.66950825E10|4.443073664E11| 3.047266067E11| 7.889611729E11| 2.488171427E11| 3.046854968E11|5.535437494E11|1.0936466697E12|6.31426982E10|   1.04788081E10|     3.7431091E9|    1.7592929E9|1.917265692028947E12|2.91509150428091E12|S1XS1311|        Q|        4.490784171029396E10|        6.849672042001608E10|         1.04792649485381E10|         1.759567786106349E9|                 3.742913407092761E9|        6.314254998698866E10|           4.687976716505064E10|                     -7.999999999999996E7|                    -4.114758088643836E7|                                 NULL|                                  NULL|                -1.601054666665822E9|                 -7.920646514696132E7|                -3.828331562511055E8|               -783064.0381237891|                                    NULL|                   -3.416855753646674E8|                  -1013397.839999999|-1.613971441697678E9|                 5.677354449590842E10|                  6.369005491075561E9|                        NULL|                         NULL|             7.88816263106127E8|             CTRY|   A|                1.34|     80.26|  200885.0|2.3612439E7|\n",
      "+-------+-----------+----+---------+-------------------+-------------------+-----------------+-----------------+-------------------+-----------------+--------------------+-----------------+------------------+----------------------+--------------------+--------------------+-----------------+---------------+-------------------+---------------+-----------------+-------------------+-----------------+-----------------+-----------------+-----------------+--------------------+----------------+-----------------+-------------------+-------------------+-----------------+--------------------+----------------+-----------------+-----------------+-----------------+-----------------+-------------------+-------------+--------------+----------------+-----------------+----------------------+---------+-------+-------+-------+----+---------+--------------+--------------+-------------+--------------+--------------+--------------+----------------+-------------+---------------+---------------+---------------+---------------+-------------+-------------+--------------+---------------+---------------+---------------+---------------+--------------+---------------+-------------+----------------+----------------+---------------+--------------------+-------------------+--------+---------+----------------------------+----------------------------+----------------------------+----------------------------+------------------------------------+----------------------------+-------------------------------+-----------------------------------------+----------------------------------------+-------------------------------------+--------------------------------------+------------------------------------+-------------------------------------+------------------------------------+---------------------------------+----------------------------------------+---------------------------------------+------------------------------------+--------------------+-------------------------------------+-------------------------------------+----------------------------+-----------------------------+-------------------------------+-----------------+----+--------------------+----------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linha = clean_df.where((clean_df.COUNTRY == \"ESP\") & (clean_df.TIME_PERIOD == \"2016-Q4\"))\n",
    "# Verifique se há mais de uma linha distinta\n",
    "if linha.count() > 1:\n",
    "    # Para cada coluna, veja quais têm valores diferentes entre as linhas\n",
    "    cols = linha.columns\n",
    "    vals = linha.collect()\n",
    "    diffs = []\n",
    "    for c in cols:\n",
    "        vset = set([row[c] for row in vals])\n",
    "        if len(vset) > 1:\n",
    "            diffs.append(c)\n",
    "    print(f\"Colunas com valores distintos: {diffs}\")\n",
    "else:\n",
    "    print(\"Só há uma linha distinta.\")\n",
    "linha = linha.distinct()\n",
    "linha.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3bcb15dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/17 12:40:42 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:40:46 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:40:57 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:41:03 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:41:07 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:41:16 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:41:21 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:41:26 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:41:35 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:41:40 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:41:44 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:41:53 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:41:59 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:42:06 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:42:15 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:42:21 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:42:26 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:42:31 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:42:35 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n",
      "25/10/17 12:42:40 WARN SQLConf: The SQL config 'spark.sql.adaptive.coalescePartitions.minPartitionNum' has been deprecated in Spark v3.2 and may be removed in the future. Use 'spark.sql.adaptive.coalescePartitions.minPartitionSize' instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_boxplots_by_country(clean_df, country=\"BRA\", title_suffix=\"DEPOIS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d83edf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'postgres_helper'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmath\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Iterable, Dict, Any, List\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpostgres_helper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_postgres_conn\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcliente_postgres\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ClientPostgresDB\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Se precisar:\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# from pyspark.sql import functions as F\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# from pyspark.sql import DataFrame as SparkDataFrame\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'postgres_helper'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/17 14:18:52 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 4915812 ms exceeds timeout 120000 ms\n",
      "25/10/17 14:18:53 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "25/10/17 14:18:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/10/17 14:18:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/10/17 14:19:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:19:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:19:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:19:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:19:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:19:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:19:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:19:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:19:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:19:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:19:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:19:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:20:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:20:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:20:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:20:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:20:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:20:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:20:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:20:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:20:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:20:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:20:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:20:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:21:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:21:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:21:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:21:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:21:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:21:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:21:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:21:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:21:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:21:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:21:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:21:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:22:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:22:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:22:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:22:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:22:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:22:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:22:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:22:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:22:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:22:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:22:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:22:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:23:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:23:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:23:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:23:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:23:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:23:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:23:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:23:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:23:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:23:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:23:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:23:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:24:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:24:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:24:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:24:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:24:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:24:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:24:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:24:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:24:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:24:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:24:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:24:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:25:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:25:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:25:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:25:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:25:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:25:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:25:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:25:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:25:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/10/17 14:25:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/10/17 14:25:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:25:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:26:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:26:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:26:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:26:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:26:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:26:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:26:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:26:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:26:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:26:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:26:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:26:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:27:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:27:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:27:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:27:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:27:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:27:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:27:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:27:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:27:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:27:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:27:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:27:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:28:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:28:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:28:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/10/17 14:28:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/10/17 14:28:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:28:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:28:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:28:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/17 14:28:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/10/17 14:28:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@172.29.99.42:45275\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/10/17 14:28:42 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "# --- imports necessários ---\n",
    "import math\n",
    "from typing import Iterable, Dict, Any, List\n",
    "\n",
    "from postgres_helper import get_postgres_conn\n",
    "from cliente_postgres import ClientPostgresDB\n",
    "\n",
    "# Se precisar:\n",
    "# from pyspark.sql import functions as F\n",
    "# from pyspark.sql import DataFrame as SparkDataFrame\n",
    "\n",
    "def _sanitize_column_name(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Saneia nomes de coluna para PostgreSQL sem aspas:\n",
    "    - minúsculas\n",
    "    - troca qualquer caractere não [a-z0-9_] por \"_\"\n",
    "    - comprime repetições de \"_\" e remove \"_\" nas pontas\n",
    "    \"\"\"\n",
    "    import re\n",
    "    s = name.lower()\n",
    "    s = re.sub(r\"[^a-z0-9_]+\", \"_\", s)\n",
    "    s = re.sub(r\"_{2,}\", \"_\", s)\n",
    "    s = s.strip(\"_\")\n",
    "    return s or \"col\"\n",
    "\n",
    "def sanitize_columns_spark(df, reserved: List[str] = None):\n",
    "    \"\"\"\n",
    "    Renomeia todas as colunas do Spark DF de modo seguro p/ Postgres (sem aspas).\n",
    "    Mantém 'country' e 'time_period' se existirem (ou converte pra minúsculas).\n",
    "    \"\"\"\n",
    "    reserved = set(reserved or [])\n",
    "    renames = {}\n",
    "    for c in df.columns:\n",
    "        new_c = _sanitize_column_name(c)\n",
    "        if c.lower() in {\"country\", \"time_period\"}:\n",
    "            new_c = c.lower()\n",
    "        # evita colisão: se já existe, anexa índice\n",
    "        base = new_c\n",
    "        i = 2\n",
    "        while new_c in renames.values():\n",
    "            new_c = f\"{base}_{i}\"\n",
    "            i += 1\n",
    "        renames[c] = new_c\n",
    "\n",
    "    out = df\n",
    "    for old, new in renames.items():\n",
    "        if old != new:\n",
    "            out = out.withColumnRenamed(old, new)\n",
    "    return out, renames\n",
    "\n",
    "def _row_to_dict(row) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Converte Spark Row -> dict \"puro\" (recursivo).\n",
    "    \"\"\"\n",
    "    d = row.asDict(recursive=True)\n",
    "    # Converte numpy types, Decimal etc. para tipos Python padrão quando necessário\n",
    "    try:\n",
    "        import numpy as np\n",
    "        for k, v in list(d.items()):\n",
    "            if isinstance(v, np.generic):\n",
    "                d[k] = v.item()\n",
    "    except Exception:\n",
    "        pass\n",
    "    return d\n",
    "\n",
    "def write_spark_to_postgres_in_batches(\n",
    "    sdf,\n",
    "    table_name: str,\n",
    "    schema: str = \"bronze\",  # ✅ Schema correto\n",
    "    conflict_fields: List[str] = None,  # ex.: [\"country\",\"time_period\"]\n",
    "    primary_key: List[str] = None,      # ex.: [\"country\",\"time_period\"]\n",
    "    batch_size: int = 10_000,\n",
    "    sanitize_columns: bool = True,\n",
    "    conn_id: str = \"postgres_dw\",  # 🔥 NOVO: usar conexão do Data Warehouse\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Envia um Spark DF ao Postgres chamando ClientPostgresDB.insert_data() em lotes.\n",
    "\n",
    "    - Sem toPandas (usa toLocalIterator)\n",
    "    - Cria a tabela automaticamente (via insert_data -> create_table_if_not_exists)\n",
    "    - Pode fazer UPSERT se conflict_fields for fornecido\n",
    "    \n",
    "    🔥 IMPORTANTE: Usa conn_id=\"postgres_dw\" para salvar no Data Warehouse!\n",
    "    \n",
    "    Schemas disponíveis no data_warehouse: staging, bronze, silver, gold\n",
    "    \"\"\"\n",
    "    # 1) Colunas: sanitizar (recomendado se você tem nomes com \"/\", espaços, etc.)\n",
    "    sdf_out = sdf\n",
    "    rename_map = {}\n",
    "    if sanitize_columns:\n",
    "        sdf_out, rename_map = sanitize_columns_spark(sdf_out)\n",
    "\n",
    "    # 2) Conexão - 🔥 USANDO A CONEXÃO CORRETA DO DATA WAREHOUSE\n",
    "    conn_str = get_postgres_conn(conn_id=conn_id)\n",
    "    client = ClientPostgresDB(conn_str)\n",
    "    \n",
    "    print(f\"[INFO] Conectando ao banco via conn_id='{conn_id}'\")\n",
    "    print(f\"[INFO] Salvando em schema='{schema}', tabela='{table_name}'\")\n",
    "\n",
    "    # 3) Iterar em lotes\n",
    "    batch: List[Dict[str, Any]] = []\n",
    "    count = 0\n",
    "\n",
    "    for row in sdf_out.toLocalIterator():  # stream sem explodir memória\n",
    "        batch.append(_row_to_dict(row))\n",
    "        if len(batch) >= batch_size:\n",
    "            client.insert_data(\n",
    "                data=batch,\n",
    "                table_name=table_name,\n",
    "                conflict_fields=conflict_fields,\n",
    "                primary_key=primary_key,\n",
    "                schema=schema,\n",
    "            )\n",
    "            count += len(batch)\n",
    "            batch.clear()\n",
    "\n",
    "    if batch:\n",
    "        client.insert_data(\n",
    "            data=batch,\n",
    "            table_name=table_name,\n",
    "            conflict_fields=conflict_fields,\n",
    "            primary_key=primary_key,\n",
    "            schema=schema,\n",
    "        )\n",
    "        count += len(batch)\n",
    "\n",
    "    print(f\"[OK] Inseridos {count} registros em {schema}.{table_name}\")\n",
    "    if rename_map:\n",
    "        print(\"[INFO] Renomeações aplicadas (Spark -> Postgres):\")\n",
    "        for k, v in rename_map.items():\n",
    "            if k != v:\n",
    "                print(f\"  - {k} -> {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88394d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔥 Exemplo de chamada - USANDO CONEXÃO CORRETA DO DATA WAREHOUSE\n",
    "write_spark_to_postgres_in_batches(\n",
    "    clean_df,\n",
    "    table_name=\"bop_clean\",                     # nome da tabela\n",
    "    schema=\"bronze\",                            # ✅ schema correto\n",
    "    conflict_fields=[\"country\",\"time_period\"],  # para UPSERT\n",
    "    primary_key=[\"country\",\"time_period\"],      # cria PK se a tabela for nova\n",
    "    batch_size=10_000,\n",
    "    sanitize_columns=True,                      # recomendado se tiver nomes com \"/\"\n",
    "    conn_id=\"postgres_dw\",                      # 🔥 CORRIGIDO: usar Data Warehouse!\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
